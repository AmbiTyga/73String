{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "25GB - Colab",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/73String/blob/main/Data%20Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6tcnzlc5v3H",
        "outputId": "4990db42-96bf-409d-d9d6-3bfd2d571599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb49crQkUaDi"
      },
      "source": [
        "!pip install scrapy -q\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "import argparse\r\n",
        "from w3lib.html import remove_tags\r\n",
        "import requests\r\n",
        "from scrapy.selector import Selector\r\n",
        "from nltk.corpus import stopwords\r\n",
        "STOPWORDS = stopwords.words('english')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Swmos9oTsC",
        "outputId": "fc2004dc-9d67-43bc-b2fd-dfd2e1898b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-14 19:22:41--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2021-02-14 19:22:41--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2021-02-14 19:22:41--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  2.08MB/s    in 17m 18s \n",
            "\n",
            "2021-02-14 19:39:59 (2.00 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6eKeFXpBgD",
        "outputId": "23919ee1-53cc-4212-9a9b-dbfbc015f77b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90R-gj1dDdX1"
      },
      "source": [
        "del STOPWORDS,argparse,glove,oov,t,vocab"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1NQkO9FsBv3"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgyI2nh54OIZ"
      },
      "source": [
        "\r\n",
        "import json, operator\r\n",
        "def load_embed(file):\r\n",
        "  '''\r\n",
        "  Loads GLoVe embeddings\r\n",
        "  file -> path to glove embeddings\r\n",
        "  load_embed(...) -> Dict()\r\n",
        "  '''\r\n",
        "  def get_coefs(word,*arr): \r\n",
        "      return word, np.asarray(arr, dtype='float32')\r\n",
        "  \r\n",
        "  if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\r\n",
        "      embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\r\n",
        "  else:\r\n",
        "      embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\r\n",
        "      \r\n",
        "  return embeddings_index\r\n",
        "  \r\n",
        "def build_vocab(texts):\r\n",
        "  '''\r\n",
        "  Creates a vocabulary from the given corpus\r\n",
        "  texts -> pandas Series object\r\n",
        "  build_vocab(...) -> Dict()\r\n",
        "  '''\r\n",
        "  sentences = texts.str.split().values\r\n",
        "  vocab = {}\r\n",
        "  for sentence in sentences:\r\n",
        "      for word in sentence:\r\n",
        "          try:\r\n",
        "              vocab[word] += 1\r\n",
        "          except KeyError:\r\n",
        "              vocab[word] = 1\r\n",
        "  return vocab\r\n",
        "\r\n",
        "# Checks how many words present in embeddings wrt dataset\r\n",
        "def check_coverage(vocab, embeddings_index):\r\n",
        "  '''\r\n",
        "  Checks the vocabulary from the given corpus with GLoVE data\r\n",
        "  Returns out of vocabulary words from corpus that are not present in GLoVE data\r\n",
        "  '''\r\n",
        "  known_words = {}\r\n",
        "  unknown_words = {}\r\n",
        "  nb_known_words = 0\r\n",
        "  nb_unknown_words = 0\r\n",
        "  for word in vocab.keys():\r\n",
        "      try:\r\n",
        "          known_words[word] = embeddings_index[word]\r\n",
        "          nb_known_words += vocab[word]\r\n",
        "      except:\r\n",
        "          unknown_words[word] = vocab[word]\r\n",
        "          nb_unknown_words += vocab[word]\r\n",
        "          pass\r\n",
        "\r\n",
        "  print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\r\n",
        "  print('Found embeddings for  {:.3%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\r\n",
        "  unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\r\n",
        "  unknown_words = pd.DataFrame(unknown_words,columns=['Word','Count'])\r\n",
        "  return unknown_words"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6o3aVUK_wPu"
      },
      "source": [
        "# t = pd.read_csv('train.csv')\r\n",
        "glove = load_embed('/content/glove.840B.300d.txt')\r\n",
        "# vocab = build_vocab(t['Short Description'])\r\n",
        "oov = check_coverage(vocab,glove)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wam77NLt6AQT",
        "outputId": "ed5d52b2-b42b-421d-8465-8fcc49c796d4"
      },
      "source": [
        "# t = pd.read_csv('train.csv')\r\n",
        "glove = load_embed('/content/glove.840B.300d.txt')\r\n",
        "# vocab = build_vocab(t['Short Description'])\r\n",
        "oov = check_coverage(vocab,glove)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 99.997% of vocab\n",
            "Found embeddings for  98.430% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRxDotBisXLK"
      },
      "source": [
        "def clean(sentence):\r\n",
        "  '''\r\n",
        "  Removes unnecessary characters from the string\r\n",
        "  And replaces the acronyms from business terms\r\n",
        "  sentence -> str\r\n",
        "  clean(...) -> str\r\n",
        "  '''\r\n",
        "  sentence = re.sub(r\"\\bcorp\\b\\.?\",'corporation',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bInc\\b\\.?\",'incorporation',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bco\\b\\.?\",'company',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bs\\.?p\\.?a\\b\\.?\",'sales and purchase agreement',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bASA\\b\\.?\",'Advertising and Selling Association',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bSA\\b\\.?\",'corporation',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bPLC\\b\\.?\",'Public Limited Company',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bAB\\b\\.?\",'Aktiebolag',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\bAG\\b\\.?\",'Aktiengesellschaft',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r\"\\be-\",'electronic ',sentence,flags = re.I)\r\n",
        "  \r\n",
        "  \r\n",
        "  sentence = re.sub(r'(â€™s)',\"'\",sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'Â',\"\",sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'\\%',\" percent\",sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'\\#',\"Number \",sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'(a-zA-Z0-9)?(\\.)(a-zA-Z0-9)?',' ',sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'\\b(\\w+)( \\1\\b)+',r'\\1', sentence)\r\n",
        "  \r\n",
        "  \r\n",
        "  sentence = re.sub(r'-',\" \",sentence,flags = re.I)\r\n",
        "  sentence = re.sub(r'[,!?\\'\\:\\(\\)\\/;]','',sentence)\r\n",
        "  sentence = re.sub(r'\\s+',\" \",sentence)\r\n",
        "\r\n",
        "  return sentence\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "def inc_info(keywords):\r\n",
        "  '''\r\n",
        "  The function googles the keywords, and returns the details from Knowledge Graph panel of Google. \r\n",
        "  '''\r\n",
        "  keywords = keywords.replace(\" \",'+')\r\n",
        "  url = f'https://www.google.com/search?&q={keywords}'\r\n",
        "\r\n",
        "  req = requests.get(url,\r\n",
        "                   headers= {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'})\r\n",
        "  details_with_tags = Selector(text = req.text).css('span.hgKElc').get()\r\n",
        "\r\n",
        "  if not details_with_tags:\r\n",
        "    details_with_tags = Selector(text = req.text).css('div.kno-rdesc span').get()\r\n",
        "\r\n",
        "  if details_with_tags:\r\n",
        "    details = remove_tags(details_with_tags)\r\n",
        "    return details\r\n",
        "\r\n",
        "def load_embed(file):\r\n",
        "  '''\r\n",
        "  Loads GLoVe embeddings\r\n",
        "  file -> path to glove embeddings\r\n",
        "  load_embed(...) -> Dict()\r\n",
        "  '''\r\n",
        "  def get_coefs(word,*arr): \r\n",
        "      return word, np.asarray(arr, dtype='float32')\r\n",
        "  \r\n",
        "  if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\r\n",
        "      embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\r\n",
        "  else:\r\n",
        "      embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\r\n",
        "      \r\n",
        "  return embeddings_index\r\n",
        "\r\n",
        "def change_term(df):\r\n",
        "  name,description = df['Company Name'], df['Short Description']\r\n",
        "  desc = []\r\n",
        "  for i,j in zip(name,description):\r\n",
        "    if i.lower() in j.lower():\r\n",
        "      j = re.sub(r'\\b{name}\\b'.format(name = i),'Company',j,flags = re.I)\r\n",
        "      desc.append(j)\r\n",
        "    else:\r\n",
        "      desc.append(j)\r\n",
        "  return desc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpxrzNo57T5m"
      },
      "source": [
        "glove = load_embed(\"/content/glove.840B.300d.txt\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHYa3gaXGTAF",
        "outputId": "83e3265f-e5c7-4f3e-e280-965e62d3a882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Business Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3rd Rock Multimedia Ltd</td>\n",
              "      <td>3rd Rock Multimedia Limited is an India-based ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andhra Petrochemicals Ltd</td>\n",
              "      <td>The Andhra Petrochemicals Limited is an India-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Force Motors Ltd</td>\n",
              "      <td>Force Motors Limited is a holding company. The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Diamines And Chemicals Ltd</td>\n",
              "      <td>Diamines and Chemicals Limited is a holding co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Insilco Ltd</td>\n",
              "      <td>Insilco Limited is engaged in manufacturing an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Company                                Business Description\n",
              "0     3rd Rock Multimedia Ltd  3rd Rock Multimedia Limited is an India-based ...\n",
              "1   Andhra Petrochemicals Ltd  The Andhra Petrochemicals Limited is an India-...\n",
              "2            Force Motors Ltd  Force Motors Limited is a holding company. The...\n",
              "3  Diamines And Chemicals Ltd  Diamines and Chemicals Limited is a holding co...\n",
              "4                 Insilco Ltd  Insilco Limited is engaged in manufacturing an..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS0a3km_sBeX"
      },
      "source": [
        "train = pd.read_excel(\"/content/Training_Data.01 (1).xlsx\")\r\n",
        "test = pd.read_excel(\"/content/Testing_Data_2_ (1).xlsx\")\r\n",
        "train.drop_duplicates('Business Description',inplace=True,ignore_index=True)\r\n",
        "train['Business Description'].fillna(train[train['Business Description'].isna()]['Company Name'].apply(inc_info),inplace = True)\r\n",
        "train.dropna(inplace = True)\r\n",
        "\r\n",
        "train['Short Description'] = train['Business Description'].apply(clean)\r\n",
        "train['Company Name'] = train['Company Name'].apply(clean)\r\n",
        "\r\n",
        "test['Short Description'] = test['Business Description'].apply(clean)\r\n",
        "test['Company Name'] = test['Company '].apply(clean)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MqZkdxGIUou"
      },
      "source": [
        "data = test.copy()\r\n",
        "\r\n",
        "data['Short Description'] = data['Short Description'].apply(lambda x: ' '.join([item for item in x.split() if item not in STOPWORDS]))\r\n",
        "data['Short Description'] = change_term(data)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYi3sD4AFQ9x"
      },
      "source": [
        "data['Short Description'] = data['Short Description'].apply(lambda x: ' '.join([\"UnkW\" if item not in glove else item for item in x.split()]))\r\n",
        "data['Short Description'] = data['Short Description'].str.replace(r'\\b(\\w+)( \\1\\b)+',r'\\1')\r\n",
        "data['Short Description'] = data['Short Description'].str.replace(r'\\bUnkW\\b','<OOV>')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MonAnzPh6tCo",
        "outputId": "54484052-240f-45c2-b076-04a6911e70c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company Name</th>\n",
              "      <th>Business Description</th>\n",
              "      <th>Industry Classification Tag</th>\n",
              "      <th>Short Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADSOUTH PARTNERS incorporation</td>\n",
              "      <td>Adsouth Partners, Inc. provides advertising ag...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company provides advertising agency services s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Artec Global Media incorporation</td>\n",
              "      <td>Artec Global Media, Inc., formerly Artec Consu...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company formerly Artec Consulting corporation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Betawave corporation</td>\n",
              "      <td>Betawave Corporation provides online marketing...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company provides online marketing solutions We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BOSTON OMAHA corporation</td>\n",
              "      <td>Boston Omaha Corporation is engaged in the bus...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company engaged business various sectors inclu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bright Mountain Media incorporation</td>\n",
              "      <td>Bright Mountain Media, Inc. is a digital media...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company digital media holding company online p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cardlytics incorporation</td>\n",
              "      <td>Cardlytics, Inc. is engaged in developing a pu...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company engaged developing purchase intelligen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CMG HOLDINGS GROUP incorporation</td>\n",
              "      <td>CMG Holdings Group, Inc. is a holding company....</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company holding company The Company sports ent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>COMSCORE incorporation</td>\n",
              "      <td>comScore, Inc. is a cross-platform measurement...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company cross platform measurement company The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Connected Media Technologies incorporation</td>\n",
              "      <td>Connected Media Technologies, Inc. is a sales ...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company sales marketing company focused digita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CREDIT ONE FINANCIAL incorporation</td>\n",
              "      <td>Credit One Financial, Inc., through its subsid...</td>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company subsidiary CEM International Ltd opera...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Company Name  ...                                  Short Description\n",
              "0              ADSOUTH PARTNERS incorporation  ...  Company provides advertising agency services s...\n",
              "1            Artec Global Media incorporation  ...  Company formerly Artec Consulting corporation ...\n",
              "2                        Betawave corporation  ...  Company provides online marketing solutions We...\n",
              "3                    BOSTON OMAHA corporation  ...  Company engaged business various sectors inclu...\n",
              "4         Bright Mountain Media incorporation  ...  Company digital media holding company online p...\n",
              "5                    Cardlytics incorporation  ...  Company engaged developing purchase intelligen...\n",
              "6            CMG HOLDINGS GROUP incorporation  ...  Company holding company The Company sports ent...\n",
              "7                      COMSCORE incorporation  ...  Company cross platform measurement company The...\n",
              "8  Connected Media Technologies incorporation  ...  Company sales marketing company focused digita...\n",
              "9          CREDIT ONE FINANCIAL incorporation  ...  Company subsidiary CEM International Ltd opera...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_brJHmV-54fp",
        "outputId": "94f2808b-3a8b-423c-f19b-6a5725999f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "data['short_words_count'] = data['Short Description'].str.split().apply(lambda x:len(x))\r\n",
        "data['short_words_count'].plot.hist()"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff049366978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjMNzQnqlCBV",
        "outputId": "8a685d87-05aa-4b1b-c129-8114b8b83227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "data.query('short_words_count>124')"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company Name</th>\n",
              "      <th>Business Description</th>\n",
              "      <th>Industry Classification Tag</th>\n",
              "      <th>Short Description</th>\n",
              "      <th>short_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>TMM incorporation</td>\n",
              "      <td>TMM, Inc., a technology company, develops and ...</td>\n",
              "      <td>Application Software</td>\n",
              "      <td>Company technology company develops distribute...</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>ABEONA THERAPEUTICS incorporation</td>\n",
              "      <td>Abeona Therapeutics Inc. is a clinical-stage b...</td>\n",
              "      <td>Biotechnology</td>\n",
              "      <td>Company clinical stage biopharmaceutical compa...</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>SavWatt USA incorporation</td>\n",
              "      <td>SavWatt USA, Inc. (SavWatt) is engaged in deve...</td>\n",
              "      <td>Electrical Components &amp; Equipment</td>\n",
              "      <td>Company SavWatt engaged developing light emitt...</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>Iamgold corporation</td>\n",
              "      <td>Iamgold Corp is a Canada-based gold mining com...</td>\n",
              "      <td>Gold</td>\n",
              "      <td>Company Canada based gold mining company The C...</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2344</th>\n",
              "      <td>Maverix Metals incorporation</td>\n",
              "      <td>Maverix Metals Inc, formerly MacMillan Mineral...</td>\n",
              "      <td>Gold</td>\n",
              "      <td>Company formerly MacMillan Minerals incorporat...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3533</th>\n",
              "      <td>Jupiter Marine International HoldingsInc</td>\n",
              "      <td>Jupiter Marine International Holdings, Inc. is...</td>\n",
              "      <td>Leisure Products</td>\n",
              "      <td>Jupiter Marine International Holdings incorpor...</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3536</th>\n",
              "      <td>Mattel incorporation</td>\n",
              "      <td>Mattel, Inc. manufactures and markets a range ...</td>\n",
              "      <td>Leisure Products</td>\n",
              "      <td>Company manufactures markets range toy product...</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4044</th>\n",
              "      <td>Pacific Ethanol incorporation</td>\n",
              "      <td>Pacific Ethanol, Inc. ist ein Produzent und Ve...</td>\n",
              "      <td>Oil &amp; Gas Refining &amp; Marketing</td>\n",
              "      <td>Company ist ein Produzent und &lt;OOV&gt; von &lt;OOV&gt; ...</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4165</th>\n",
              "      <td>Hot Mamas Foods incorporation</td>\n",
              "      <td>Hot Mamas Foods Inc. is engaged in the busines...</td>\n",
              "      <td>Packaged Foods &amp; Meats</td>\n",
              "      <td>Company engaged business manufacturing gourmet...</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Company Name  ... short_words_count\n",
              "523                          TMM incorporation  ...               140\n",
              "705          ABEONA THERAPEUTICS incorporation  ...               128\n",
              "1951                 SavWatt USA incorporation  ...               137\n",
              "2297                       Iamgold corporation  ...               125\n",
              "2344              Maverix Metals incorporation  ...               131\n",
              "3533  Jupiter Marine International HoldingsInc  ...               133\n",
              "3536                      Mattel incorporation  ...               128\n",
              "4044             Pacific Ethanol incorporation  ...               130\n",
              "4165             Hot Mamas Foods incorporation  ...               129\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta0wVV8Hul_M"
      },
      "source": [
        "t = pd.read_csv('train.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy78fEF9upjk",
        "outputId": "408a2cd9-8507-42e7-dbe9-a4a83650c6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "t.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Industry Classification Tag</th>\n",
              "      <th>Short Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company provides advertising agency services s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company formerly Artec Consulting corporation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company provides online marketing solutions We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company engaged business various sectors inclu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Advertising</td>\n",
              "      <td>Company digital media holding company online p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Industry Classification Tag                                  Short Description\n",
              "0                 Advertising  Company provides advertising agency services s...\n",
              "1                 Advertising  Company formerly Artec Consulting corporation ...\n",
              "2                 Advertising  Company provides online marketing solutions We...\n",
              "3                 Advertising  Company engaged business various sectors inclu...\n",
              "4                 Advertising  Company digital media holding company online p..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfecQyfISKJ"
      },
      "source": [
        "# Building Vocab and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyW4AvFzIVR4"
      },
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\r\n",
        "test = pd.read_csv(\"/content/test.csv\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEnD3xSzIeK1"
      },
      "source": [
        "del data\r\n",
        "data = pd.concat([train['Short Description'],\r\n",
        "                  test['Short Description']],ignore_index = True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy-OFYlyJvf7",
        "outputId": "bd042061-0b03-48d5-cae3-5cd6bc3248bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "glove['A']"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0996e-01, -1.5577e-01, -3.7736e-01,  2.2892e-01, -1.4712e-01,\n",
              "       -4.1782e-01, -1.9491e-01,  6.1021e-02,  5.7944e-02,  7.9813e-01,\n",
              "       -4.9189e-01,  2.6116e-02,  1.6173e-01,  2.8898e-01, -2.6319e-03,\n",
              "       -1.8420e-01, -8.7295e-02,  1.8144e+00, -1.4008e-01,  2.3612e-01,\n",
              "       -7.5722e-03, -4.4965e-01, -8.9656e-02,  2.7359e-01,  2.0097e-01,\n",
              "       -7.2507e-03,  8.5632e-02, -2.5656e-02,  7.4721e-02, -4.6209e-01,\n",
              "       -7.2882e-02, -1.6263e-01,  4.3647e-01, -2.2789e-01,  6.8795e-01,\n",
              "        5.2565e-02,  6.9874e-01, -2.6120e-01, -2.0619e-01, -5.6306e-01,\n",
              "        6.7343e-01,  7.3758e-01,  5.6451e-01, -6.2426e-02,  1.7391e-01,\n",
              "       -4.3643e-01, -2.8697e-01, -4.3337e-01, -4.9453e-03,  1.5617e-01,\n",
              "       -3.4879e-01,  3.7111e-01,  1.1258e-01,  2.5172e-01, -3.1563e-02,\n",
              "        3.0049e-01,  4.4813e-01, -1.5333e-02,  1.6217e-01, -4.8068e-01,\n",
              "        7.2301e-02,  6.1309e-01,  3.4949e-01,  2.1502e-01, -7.2819e-02,\n",
              "       -2.1604e-01, -7.5218e-03,  2.7666e-01, -6.7807e-02,  8.0486e-01,\n",
              "       -6.9778e-02, -1.9350e-02, -8.0579e-02, -1.4039e-02, -1.7270e-01,\n",
              "       -3.6490e-01,  3.3739e-02, -4.0203e-01, -4.2697e-01, -1.5293e-01,\n",
              "       -2.7655e-01, -1.5369e-02,  2.3901e-01, -3.1599e-01, -2.9107e-02,\n",
              "       -2.1087e-01, -9.6182e-01, -6.4057e-01,  1.9498e-01, -1.8121e-02,\n",
              "        3.1116e-02,  5.4894e-01, -3.0120e-01, -5.1079e-01, -3.5858e-01,\n",
              "        2.8914e-01, -2.4464e-04,  1.3136e-01,  3.3373e-01,  1.0972e-01,\n",
              "       -3.8792e-01,  1.0509e-01, -9.6306e-02, -3.0380e-01, -5.2376e-01,\n",
              "        1.2378e+00,  1.2279e-01, -7.8918e-02, -1.2906e-01, -2.9315e-01,\n",
              "        5.0429e-01,  4.6874e-01,  3.4198e-01,  2.0860e-01, -2.0838e-01,\n",
              "        1.3765e-01, -3.9630e-01,  1.8899e-01,  2.1267e-02,  2.7989e-01,\n",
              "        8.1349e-02, -1.0532e-01, -1.6893e-01, -1.9626e-01,  3.4535e-01,\n",
              "        7.5704e-02,  1.6554e-01,  2.3067e-01, -7.8467e-01,  3.3482e-01,\n",
              "        1.8541e-01,  2.1629e-02,  2.4324e-01,  1.6439e-01, -2.0480e-01,\n",
              "        3.1068e-01, -2.9248e-01, -3.5154e-01,  2.8416e-01, -3.6905e-01,\n",
              "       -6.8219e-01,  4.0374e-01,  9.4617e-02,  2.1020e-01, -2.0161e-01,\n",
              "       -5.6048e-01, -1.9860e-01,  1.0270e-02,  5.3890e-01, -1.2267e-01,\n",
              "        5.9360e-02,  5.5474e-01, -3.1224e-01,  4.8796e-01, -1.2043e-01,\n",
              "        4.6766e-01, -1.2938e-01,  4.0088e-01,  1.9864e-02, -2.9511e-01,\n",
              "       -2.5855e-01, -7.4660e-02,  2.8590e-01,  3.1425e-01,  6.0800e-03,\n",
              "       -2.1354e-01, -2.1682e-02,  7.1712e-04,  1.4667e-01,  1.6867e-01,\n",
              "        2.2643e-01, -6.4471e-02,  3.7709e-01, -5.5989e-01,  8.0315e-02,\n",
              "       -3.8040e-01,  4.1056e-01,  2.4063e-01,  2.4484e-01, -8.4154e-02,\n",
              "       -3.3520e-01, -2.0211e-01,  3.1680e-01, -2.1769e-01, -8.7743e-02,\n",
              "       -2.9136e-01, -3.8373e-01,  3.1967e-01, -2.1597e-01, -6.3323e-01,\n",
              "       -5.5495e-01,  2.3800e-01, -1.7380e-01,  1.5924e-01, -1.9654e-02,\n",
              "       -2.3382e-01, -4.1693e-01, -2.7608e-02, -4.6920e-01, -1.8673e-01,\n",
              "        8.0305e-02,  1.8432e-01, -2.7526e-01, -1.1773e-01, -7.8136e-02,\n",
              "        4.4391e-05,  7.5786e-02, -1.1134e-01, -2.8653e-02, -6.6874e-02,\n",
              "       -1.0825e-01,  3.3274e-01, -5.3809e-01,  8.4754e-02,  2.4742e-01,\n",
              "        4.9225e-01, -6.1612e-01, -7.3305e-02,  3.6984e-02, -4.7666e-01,\n",
              "        3.8760e-01, -1.1847e-01, -1.8543e-01,  2.6648e-01,  3.0100e-02,\n",
              "       -9.1692e-02, -8.9048e-02,  5.9740e-01, -3.4772e-01,  4.2589e-02,\n",
              "        3.5159e-01,  5.4349e-01,  3.9836e-02, -1.3209e-01, -1.1680e-01,\n",
              "       -1.7365e-01,  2.7153e-01, -2.4718e-01, -2.9161e-01,  3.7760e-01,\n",
              "       -1.8952e-01, -1.9703e-01,  4.6173e-01, -3.8895e-01, -1.3167e-01,\n",
              "        4.1821e-01,  1.8999e-01, -4.2373e-01,  1.4842e-01, -2.2686e-02,\n",
              "       -1.7622e-01, -4.2518e-01,  2.6350e-01,  2.7572e-01,  2.1108e-02,\n",
              "        2.2420e-01,  3.3604e-01, -6.2737e-01,  1.4957e-01,  1.1675e-01,\n",
              "       -1.4058e-01,  2.7587e-01,  4.8029e-01,  1.5128e-01,  1.6701e-01,\n",
              "       -2.2638e-01,  5.0567e-01,  3.1768e-01,  2.5475e-01, -3.9161e-01,\n",
              "       -4.2438e-01, -1.7821e-01, -1.7495e-01, -5.7828e-01, -8.6497e-02,\n",
              "       -2.2157e-01, -4.5225e-01, -1.0178e-01,  4.7447e-01,  4.2666e-01,\n",
              "        3.2293e-01,  1.8973e-01, -1.3945e-01,  2.4426e-01, -3.0392e-01,\n",
              "       -2.6029e-01, -1.5535e-01, -2.2362e-01,  4.3117e-02, -1.4086e-01,\n",
              "       -6.4447e-02, -6.4530e-02, -2.9109e-01, -4.9615e-02,  2.1072e-01,\n",
              "        3.4463e-01,  4.1230e-01, -5.5673e-01,  7.2776e-04,  6.5055e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D2LqXiLJDCt"
      },
      "source": [
        "vocab = build_vocab(data)\r\n",
        "embeddings = dict()\r\n",
        "glove['<OOV>'] = np.random.rand(300)\r\n",
        "for i in vocab:\r\n",
        "  embeddings[i] = glove[i]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJJyiYtnKFQV",
        "outputId": "aac2126e-a2af-434f-d038-b1866be9c1f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(),len(glove)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39066, 2196017)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTZJGbVsASJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y5EONb-Txmn"
      },
      "source": [
        "class GloveTokenizer:\r\n",
        "    def __init__(self, vectors, unk='<OOV>', pad='<pad>'):\r\n",
        "        # self.vectors = vectors\r\n",
        "        self.unk = unk\r\n",
        "        self.pad = pad\r\n",
        "        self.stoi = dict()\r\n",
        "        self.itos = dict()\r\n",
        "        self.embedding_matrix = list()\r\n",
        "        # with open(filename, 'r', encoding='utf8') as f: # Read tokenizer file\r\n",
        "        for i, embed in enumerate(vectors):\r\n",
        "            # values = line.split(\" \")\r\n",
        "            self.stoi[embed] = i\r\n",
        "            self.itos[i] = embed\r\n",
        "            self.embedding_matrix.append(vectors[embed])\r\n",
        "        if self.unk is not None: # Add unk token into the tokenizer\r\n",
        "            i += 1\r\n",
        "            self.stoi[self.unk] = i\r\n",
        "            self.itos[i] = self.unk\r\n",
        "            self.embedding_matrix.append(np.random.rand(len(self.embedding_matrix[0])))\r\n",
        "        if self.pad is not None: # Add pad token into the tokenizer\r\n",
        "            i += 1\r\n",
        "            self.stoi[self.pad] = i\r\n",
        "            self.itos[i] = self.pad\r\n",
        "            self.embedding_matrix.append(np.zeros(len(self.embedding_matrix[0])))\r\n",
        "        self.embedding_matrix = np.array(self.embedding_matrix).astype(np.float32) # Convert if from double to float for efficiency\r\n",
        "\r\n",
        "    def encode(self, sentence):\r\n",
        "        if type(sentence) == str:\r\n",
        "            sentence = sentence.split(' ')\r\n",
        "        elif len(sentence): # Convertible to list\r\n",
        "            sentence = list(sentence)\r\n",
        "        else:\r\n",
        "            raise TypeError('sentence should be either a str or a list of str!')\r\n",
        "        encoded_sentence = []\r\n",
        "        for word in sentence:\r\n",
        "            encoded_sentence.append(self.stoi.get(word, self.stoi[self.unk]))\r\n",
        "        return encoded_sentence\r\n",
        "\r\n",
        "    def decode(self, encoded_sentence):\r\n",
        "        try:\r\n",
        "            encoded_sentence = list(encoded_sentence)\r\n",
        "        except Exception as e:\r\n",
        "            print(e)\r\n",
        "            raise TypeError('encoded_sentence should be either a str or a data type that is convertible to list type!')\r\n",
        "        sentence = []\r\n",
        "        for encoded_word in encoded_sentence:\r\n",
        "            sentence.append(self.itos[encoded_word])\r\n",
        "        return sentence\r\n",
        "\r\n",
        "    def embedding(self, encoded_sentence):\r\n",
        "        return self.embedding_matrix[np.array(encoded_sentence)]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "082SFJgFO3em",
        "outputId": "1411a1f3-f336-4124-92be-26e28f5caf29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(train['Industry Classification Tag'].values)\r\n",
        "le.transform(['Trading Companies & Distributors'])\r\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([61])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07sqtijCSfRe",
        "outputId": "9b606e38-f4df-459c-da45-c7b36640c65e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.to_numpy()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Advertising',\n",
              "        'Company provides advertising agency services specializing direct response media campaigns It also owns distribution rights number products acquired The business consists two operating sectors advertising products During year ended December 31 2005 internally developed marketed two lines flashlights branded Extreme Beam Flashlight Clip Light The Company obtained exclusive five year marketing distribution rights Hercules Hook distribution rights D Shed PEARL Anti Wrinkle Moisturizing Mist 2005 In 2005 Company also organized Genco Power Solutions incorporation Genco purpose marketing selling installing servicing integrated power generator systems residential homeowners commercial business throughout Florida The Company owns 66 percent Genco'],\n",
              "       ['Advertising',\n",
              "        'Company formerly Artec Consulting corporation marketing firm The Company provides online marketing reporting solutions including lead generation performance media affiliate marketing related Web services consultation Its segments include online marketing media services It owns accesses targeted databases utilizes technology create local regional national marketing campaigns demand providing clients ability acquire new customers It runs advertisements forms marketing messages programs multiple channels electronic mail direct mail social media short message service SMS radio telecommunication create responders client offerings Its marketing services include affiliate performance marketing display advertising electronic mail marketing lead generation creative design consulting services It also engaged student loan debt consultation business'],\n",
              "       ['Advertising',\n",
              "        'Company provides online marketing solutions Websites targeting youth moms The Company specializes aggregating distributing marketing content selected network targeted sites mostly virtual worlds gaming GoFish exclusive brand advertising monetization partner GoFish provides services planning buying execution ad campaigns GoFish also provides online videos targeting teen audience'],\n",
              "       ...,\n",
              "       ['Trading Companies & Distributors',\n",
              "        'Company formerly Mineria Y <OOV> Olympia incorporation subsidiary Bosch International LLC BIL distributes nanotechnology printed light sheets entertainment sector including movie theaters movie studios production distribution companies talent management agencies marketing public relations firms outdoor media United States Canada Caribbean The Company also purchased rights distribute light sheets automotive sector distribute nanotechnology printed solar panels nanotechnology printed batteries The Company distribution rights <OOV> com <OOV> program allows movies talent businesses promotions introduced audience motion picture quality As April 2016 Company placed light sheets 250 theater locations United States'],\n",
              "       ['Trading Companies & Distributors',\n",
              "        'Company scrap steel processor The Company engaged importing selling distributing metal refinery industry China range metal ore including iron chrome nickel titanium copper manganese ore well non ferrous metals coal It also recycles scrap metal used steel mills production recycled steel It also trades raw wood barley Its subsidiaries include Armco Metal International Limited Henan Armco <OOV> Trading company Ltd engage import export distribution ferrous non ferrous ore metals Armco Lianyungang Renewable Metals incorporation engages processing distribution scrap metal Armco Lianyungang Holdings incorporation focuses marketing distribution recycled scrap steel Armco Metals Shanghai Holdings Ltd oversees activities Company financing international trading'],\n",
              "       ['Trading Companies & Distributors',\n",
              "        'Company specialty distributor wallboard suspended ceiling systems United States Canada The Company fabricates distributes products specialty contractors seeking improve maintain energy efficiency range commercial industrial buildings It serves markets across United States Canada It distributes wallboard accessories metal framing suspended ceiling systems products Other products include stucco Exterior insulation finish system EIFS well offerings tools safety accessories fasteners']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5CbKYEsUGyK"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "class TextLevelGNNDataset(Dataset): # For instantiating train, validation and test dataset\r\n",
        "    def __init__(self, node_sets, neighbor_sets, public_edge_mask, labels):\r\n",
        "        super(TextLevelGNNDataset).__init__()\r\n",
        "        self.node_sets = node_sets\r\n",
        "        self.neighbor_sets = neighbor_sets\r\n",
        "        self.public_edge_mask = public_edge_mask\r\n",
        "        self.labels = labels\r\n",
        "\r\n",
        "    def __getitem__(self, i):\r\n",
        "        return torch.LongTensor(self.node_sets[i]), \\\r\n",
        "               torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1), \\\r\n",
        "               self.public_edge_mask[torch.LongTensor(self.node_sets[i]).unsqueeze(-1).repeat(1, torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1).shape[-1]), torch.nn.utils.rnn.pad_sequence([torch.LongTensor(neighbor) for neighbor in self.neighbor_sets[i]], batch_first=True, padding_value=1)], \\\r\n",
        "               torch.LongTensor(self.labels[i])\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.labels)\r\n",
        "\r\n",
        "\r\n",
        "class TextLevelGNNDatasetClass: # This class is used to achieve parameters sharing among datasets\r\n",
        "    def __init__(self, train_filename, tokenizer, MAX_LENGTH=10, p=2, min_freq=2, train_validation_split=0.8):\r\n",
        "        self.train_filename = train_filename\r\n",
        "        # self.test_filename = test_filename\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.MAX_LENGTH = MAX_LENGTH\r\n",
        "        self.p = p\r\n",
        "        self.min_freq = min_freq\r\n",
        "        self.train_validation_split = train_validation_split\r\n",
        "        self.le = LabelEncoder()\r\n",
        "        # self.train_data = pd.read_csv(self.train_filename, header=None)\r\n",
        "        # self.test_data = pd.read_csv(self.test_filename, header=None)\r\n",
        "        \r\n",
        "        self.train_data = pd.read_csv(self.train_filename)\r\n",
        "\r\n",
        "\r\n",
        "        self.stoi = {'<OOV>': 0, '<pad>': 1} # Re-index\r\n",
        "        self.itos = {0: '<OOV>', 1: '<pad>'} # Re-index\r\n",
        "        self.vocab_count = len(self.stoi)\r\n",
        "        self.embedding_matrix = None\r\n",
        "        self.le.fit(self.train_data['Industry Classification Tag'].values)\r\n",
        "        # self.label_dict = dict(zip(self.train_data['Industry Classification Tag'].unique(), pd.get_dummies(self.train_data['Industry Classification Tag'].unique()).values.tolist())) # make changes her\r\n",
        "\r\n",
        "        self.train_dataset, self.validation_dataset = random_split(self.train_data.to_numpy(), [int(len(self.train_data) * train_validation_split), len(self.train_data) - int(len(self.train_data) * train_validation_split)])\r\n",
        "        # self.test_dataset = self.test_data.to_numpy()\r\n",
        "\r\n",
        "        self.build_vocab() # Based on train_dataset only. Updates self.stoi, self.itos, self.vocab_count and self.embedding_matrix\r\n",
        "\r\n",
        "        # self.train_dataset, self.validation_dataset, self.test_dataset, self.edge_stat, self.public_edge_mask = self.prepare_dataset()\r\n",
        "        self.train_dataset, self.validation_dataset, self.edge_stat, self.public_edge_mask = self.prepare_dataset()\r\n",
        "\r\n",
        "    def build_vocab(self):\r\n",
        "        vocab_list = [sentence.split(' ') for _, sentence in self.train_dataset]\r\n",
        "        unique_vocab = []\r\n",
        "        for vocab in vocab_list:\r\n",
        "            unique_vocab.extend(vocab)\r\n",
        "        unique_vocab = list(set(unique_vocab))\r\n",
        "        for vocab in unique_vocab:\r\n",
        "            if vocab in self.tokenizer.stoi.keys():\r\n",
        "                self.stoi[vocab] = self.vocab_count\r\n",
        "                self.itos[self.vocab_count] = vocab\r\n",
        "                self.vocab_count += 1\r\n",
        "        self.embedding_matrix = self.tokenizer.embedding(self.tokenizer.encode(list(self.stoi.keys())))\r\n",
        "\r\n",
        "    def prepare_dataset(self): # will also build self.edge_stat and self.public_edge_mask\r\n",
        "        # preparing self.train_dataset\r\n",
        "        node_sets = [[self.stoi.get(vocab, 0) for vocab in sentence.strip().split(' ')][:self.MAX_LENGTH] for _, sentence in self.train_dataset] # Only retrieve the first MAX_LENGTH words in each document\r\n",
        "        neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\r\n",
        "        labels = [self.le.transform([label])[0] for label,_ in self.train_dataset]\r\n",
        "        print('At TextLevelGNN Class')\r\n",
        "        print(labels)\r\n",
        "        # Construct edge statistics and public edge mask\r\n",
        "        edge_stat, public_edge_mask = self.build_public_edge_mask(node_sets, neighbor_sets, min_freq=self.min_freq)\r\n",
        "        \r\n",
        "        train_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\r\n",
        "\r\n",
        "        # preparing self.validation_dataset\r\n",
        "        node_sets = [[self.stoi.get(vocab, 0) for vocab in sentence.strip().split(' ')][:self.MAX_LENGTH] for _, sentence in self.validation_dataset] # Only retrieve the first MAX_LENGTH words in each document\r\n",
        "        neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\r\n",
        "        labels = [self.le.transform([label])[0] for label,_ in self.validation_dataset]\r\n",
        "        validation_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\r\n",
        "        print(labels)\r\n",
        "        print(500*'-')\r\n",
        "        # # preparing self.test_dataset\r\n",
        "        # node_sets = [[self.stoi.get(vocab, 0) for vocab in sentence.strip().split(' ')][:self.MAX_LENGTH] for _, sentence, _ in self.test_dataset] # Only retrieve the first MAX_LENGTH words in each document\r\n",
        "        # neighbor_sets = [create_neighbor_set(node_set, p=self.p) for node_set in node_sets]\r\n",
        "        # labels = [self.label_dict[label] for _,_,label in self.test_dataset]\r\n",
        "        # test_dataset = TextLevelGNNDataset(node_sets, neighbor_sets, public_edge_mask, labels)\r\n",
        "\r\n",
        "        # return train_dataset, validation_dataset, test_dataset, edge_stat, public_edge_mask\r\n",
        "        return train_dataset, validation_dataset, edge_stat, public_edge_mask\r\n",
        "\r\n",
        "    def build_public_edge_mask(self, node_sets, neighbor_sets, min_freq=2):\r\n",
        "        edge_stat = torch.zeros(self.vocab_count, self.vocab_count)\r\n",
        "        for node_set, neighbor_set in zip(node_sets, neighbor_sets):\r\n",
        "            for neighbor in neighbor_set:\r\n",
        "                for to_node in neighbor:\r\n",
        "                    edge_stat[node_set, to_node] += 1\r\n",
        "        public_edge_mask = edge_stat < min_freq # mark True at uncommon edges\r\n",
        "        return edge_stat, public_edge_mask\r\n",
        "\r\n",
        "\r\n",
        "def create_neighbor_set(node_set, p=2):\r\n",
        "    if type(node_set[0]) != int:\r\n",
        "        raise ValueError('node_set should be a 1D list!')\r\n",
        "    if p < 0:\r\n",
        "        raise ValueError('p should be an integer >= 0!')\r\n",
        "    sequence_length = len(node_set)\r\n",
        "    neighbor_set = []\r\n",
        "    for i in range(sequence_length):\r\n",
        "        neighbor = []\r\n",
        "        for j in range(-p, p+1):\r\n",
        "            if 0 <= i + j < sequence_length:\r\n",
        "                neighbor.append(node_set[i+j])\r\n",
        "        neighbor_set.append(neighbor)\r\n",
        "    return neighbor_set"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI7m2TKnRBv9",
        "outputId": "f9303919-d39e-4a16-fdb0-49c58166d475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     3395342848, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139706696204288,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      0, 139702401236992,               0, 139702401236992,\n",
              "                      1,               1,               1,               1,\n",
              "                      1,               1,               1,               1,\n",
              "                      1,               1,               1,               1],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZmSkBMiTQMX",
        "outputId": "41a27dd4-7fd1-42e4-efb5-29e247e2db3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.nn.utils.rnn.pad_sequence(torch.tensor([[10]]), batch_first=True, padding_value=1)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-yIjfKMUSKv"
      },
      "source": [
        "def pad_custom_sequence(sequences):\r\n",
        "    '''\r\n",
        "    To pad different sequences into a padded tensor for training. The main purpose of this function is to separate different sequence, pad them in different ways and return padded sequences.\r\n",
        "    Input:\r\n",
        "        sequences <list>: A sequence with a length of 4, representing the node sets sequence in index 0, neighbor sets sequence in index 1, public edge mask sequence in index 2 and label sequence in index 3.\r\n",
        "                          And the length of each sequences are same as the batch size.\r\n",
        "                          sequences: [node_sets_sequence, neighbor_sets_sequence, public_edge_mask_sequence, label_sequence]\r\n",
        "    Return:\r\n",
        "        node_sets_sequence <torch.LongTensor>: The padded node sets sequence (works with batch_size >= 1).\r\n",
        "        neighbor_sets_sequence <torch.LongTensor>: The padded neighbor sets sequence (works with batch_size >= 1).\r\n",
        "        public_edge_mask_sequence <torch.BoolTensor>: The padded public edge mask sequence (works with batch_size >= 1).\r\n",
        "        label_sequence <torch.FloatTensor>: The padded label sequence (works with batch_size >= 1).\r\n",
        "    '''\r\n",
        "    node_sets_sequence = []\r\n",
        "    neighbor_sets_sequence = []\r\n",
        "    public_edge_mask_sequence = []\r\n",
        "    label_sequence = []\r\n",
        "    for node_sets, neighbor_sets, public_edge_mask, label in sequences:\r\n",
        "        node_sets_sequence.append(node_sets)\r\n",
        "        neighbor_sets_sequence.append(neighbor_sets)\r\n",
        "        public_edge_mask_sequence.append(public_edge_mask)\r\n",
        "        label_sequence.append(label)\r\n",
        "    node_sets_sequence = torch.nn.utils.rnn.pad_sequence(node_sets_sequence, batch_first=True, padding_value=1)\r\n",
        "    neighbor_sets_sequence, _ = padding_tensor(neighbor_sets_sequence)\r\n",
        "    public_edge_mask_sequence, _ = padding_tensor(public_edge_mask_sequence)\r\n",
        "    print(\"At pad custom sequence\")\r\n",
        "    print(label_sequence)\r\n",
        "    label_sequence = torch.nn.utils.rnn.pad_sequence(label_sequence, batch_first=True, padding_value=1)\r\n",
        "    \r\n",
        "    print(label_sequence)\r\n",
        "    return node_sets_sequence, neighbor_sets_sequence, public_edge_mask_sequence, label_sequence\r\n",
        "\r\n",
        "\r\n",
        "def padding_tensor(sequences, padding_idx=1):\r\n",
        "    '''\r\n",
        "    To pad tensor of different shape to be of the same shape, i.e. padding [tensor.rand(2, 3), tensor.rand(3, 5)] to a shape (2, 3, 5), where 0th dimension is batch_size, 1st and 2nd dimensions are padded.\r\n",
        "    Input:\r\n",
        "        sequences <list>: A list of tensors\r\n",
        "        padding_idx <int>: The index that corresponds to the padding index\r\n",
        "    Return:\r\n",
        "        out_tensor <torch.tensor>: The padded tensor\r\n",
        "        mask <torch.tensor>: A boolean torch tensor where 1 (represents '<pad>') are marked as true\r\n",
        "    '''\r\n",
        "    num = len(sequences)\r\n",
        "    max_len_0 = max([s.shape[0] for s in sequences])\r\n",
        "    max_len_1 = max([s.shape[1] for s in sequences])\r\n",
        "    out_dims = (num, max_len_0, max_len_1)\r\n",
        "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_idx)\r\n",
        "    for i, tensor in enumerate(sequences):\r\n",
        "        len_0 = tensor.size(0)\r\n",
        "        len_1 = tensor.size(1)\r\n",
        "        out_tensor[i, :len_0, :len_1] = tensor\r\n",
        "    mask = out_tensor == padding_idx # Marking all places with padding_idx as mask\r\n",
        "    return out_tensor, mask"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB1wKg7JUN5Y"
      },
      "source": [
        "\r\n",
        "class MessagePassing(nn.Module):\r\n",
        "    def __init__(self, vertice_count, input_size, out_size, dropout_rate=0, padding_idx=1):\r\n",
        "        super(MessagePassing, self).__init__()\r\n",
        "        self.vertice_count = vertice_count # |V|\r\n",
        "        self.input_size = input_size # d\r\n",
        "        self.out_size = out_size # c\r\n",
        "        self.dropout_rate = dropout_rate\r\n",
        "        self.padding_idx = padding_idx\r\n",
        "        self.information_rate = nn.Parameter(torch.rand(self.vertice_count, 1)) # (|V|, 1), which means it is a column vector\r\n",
        "        self.linear = nn.Linear(self.input_size, self.out_size) # (d, c)\r\n",
        "        self.dropout = nn.Dropout(self.dropout_rate)\r\n",
        "\r\n",
        "    def forward(self, node_sets, embedded_node, edge_weight, embedded_neighbor_node):\r\n",
        "        # node_sets: (batch_size, l)\r\n",
        "        # embedded_node: (batch_size, l, d)\r\n",
        "        # edge_weight: (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        # embedded_neighbor_node: (batch_size, max_sentence_length, max_neighbor_count, d)\r\n",
        "\r\n",
        "        tmp_tensor = (edge_weight.view(-1, 1) * embedded_neighbor_node.view(-1, self.input_size)).view(embedded_neighbor_node.shape) # (batch_size, max_sentence_length, max_neighbor_count, d)\r\n",
        "        tmp_tensor = tmp_tensor.masked_fill(tmp_tensor == 0, -1e18) # (batch_size, max_sentence_length, max_neighbor_count, d), mask for M such that masked places are marked as -1e18\r\n",
        "        tmp_tensor = self.dropout(tmp_tensor)\r\n",
        "        M = tmp_tensor.max(dim=2)[0] # (batch_size, max_sentence_length, d), which is same shape as embedded_node (batch_size, l, d)\r\n",
        "        information_rate = self.information_rate[node_sets] # (batch_size, l, 1)\r\n",
        "        information_rate = information_rate.masked_fill((node_sets == self.padding_idx).unsqueeze(-1), 1) # (batch_size, l, 1), Fill the information rate of the padding index as 1, such that new e_n = (1-i_r) * M + i_r * e_n = (1-1) * 0 + 1 * e_n = e_n (no update)\r\n",
        "        embedded_node = (1 - information_rate) * M + information_rate * embedded_node # (batch_size, l, d)\r\n",
        "        sum_embedded_node = embedded_node.sum(dim=1) # (batch_size, d)\r\n",
        "        x = F.relu(self.linear(sum_embedded_node)) # (batch_size, c)\r\n",
        "#         x = self.dropout(x) # if putting dropout with p=0.5 here, it is equivalent to wiping 4 choices out of 8 choices on the question sheet, which does not make sense. If a dropout layer is placed at here, it works the best when p=0 (disabled), followed by p=0.05, ..., p=0.5 (worst and does not even converge).\r\n",
        "        y = F.softmax(x, dim=1) # (batch_size, c) along the c dimension\r\n",
        "        return y\r\n",
        "\r\n",
        "\r\n",
        "class TextLevelGNN(nn.Module):\r\n",
        "    def __init__(self, pretrained_embeddings, out_size=8, dropout_rate=0, padding_idx=1):\r\n",
        "        super(TextLevelGNN, self).__init__()\r\n",
        "        self.out_size = out_size # c\r\n",
        "        self.padding_idx = padding_idx\r\n",
        "        self.weight_matrix = nn.Parameter(torch.randn(pretrained_embeddings.shape[0], pretrained_embeddings.shape[0])) # (|V|, |V|)        \r\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False, padding_idx=self.padding_idx) # (|V|, d)\r\n",
        "        self.message_passing = MessagePassing(vertice_count=pretrained_embeddings.shape[0], input_size=pretrained_embeddings.shape[1], out_size=self.out_size, dropout_rate=dropout_rate, padding_idx=self.padding_idx) # input_size: (d,); out_size: (c,)\r\n",
        "        self.public_edge_weight = nn.Parameter(torch.randn(1, 1)) # (1, 1)\r\n",
        "\r\n",
        "    def forward(self, node_sets, neighbor_sets, public_edge_mask):\r\n",
        "        # node_sets: (batch_size, l)\r\n",
        "        # neighbor_sets: (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        # neighbor_sets_mask: (batch_size, max_sentence_length, max_neighbor_count) (no need)\r\n",
        "        # public_edge_mask: (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "\r\n",
        "        embedded_node = self.embedding(node_sets) # (batch_size, l, d)\r\n",
        "        edge_weight = model.weight_matrix[node_sets.unsqueeze(2).repeat(1, 1, neighbor_sets.shape[-1]), neighbor_sets] # (batch_size, max_sentence_length, max_neighbor_count), neighbor_sets.shape[-1]: eg p=2, this expression=5; p=3, this expression=7. This is to first make node_sets to have same shape with neighbor_sets, then just do 1 query instead of 32*100 queries to speed up performance\r\n",
        "        a = edge_weight * ~public_edge_mask # (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        b = self.public_edge_weight.unsqueeze(2).expand(1, public_edge_mask.shape[-2], public_edge_mask.shape[-1]) * public_edge_mask # (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        edge_weight = a + b # (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        embedded_neighbor_node = self.embedding(neighbor_sets) # (batch_size, max_sentece_length, max_neighbor_count, d)\r\n",
        "\r\n",
        "        # Apply mask to edge_weight, to mask and cut-off any relationships to the padding nodes\r\n",
        "        edge_weight = edge_weight.masked_fill((node_sets.unsqueeze(2).repeat(1, 1, neighbor_sets.shape[-1]) == self.padding_idx) | (neighbor_sets == self.padding_idx), 0) # (batch_size, max_sentence_length, max_neighbor_count)\r\n",
        "        x = self.message_passing(node_sets, embedded_node, edge_weight, embedded_neighbor_node) # (batch_size, c)\r\n",
        "        return x\r\n",
        "\r\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_Ctqz5fiek"
      },
      "source": [
        "tokenizer = GloveTokenizer(embeddings)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slNsuw07A_IM",
        "outputId": "0cbd35bd-95ff-4b33-a05b-7f353518a605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = TextLevelGNNDatasetClass(train_filename='/content/train.csv',\r\n",
        "                                   train_validation_split=0.9,\r\n",
        "                                   tokenizer=tokenizer,\r\n",
        "                                   MAX_LENGTH=124)\r\n",
        "train_loader = DataLoader(dataset.train_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence)\r\n",
        "validation_loader = DataLoader(dataset.validation_dataset, batch_size=32, shuffle=True, collate_fn=pad_custom_sequence)\r\n",
        "\r\n",
        "device = torch.device(f'cuda:0')\r\n",
        "model = TextLevelGNN(pretrained_embeddings=torch.tensor(dataset.embedding_matrix), dropout_rate=0.45).to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At TextLevelGNN Class\n",
            "[44, 40, 60, 26, 17, 4, 25, 7, 10, 36, 17, 47, 55, 2, 50, 47, 42, 58, 46, 21, 53, 50, 33, 50, 45, 38, 43, 7, 56, 47, 15, 59, 27, 48, 47, 33, 2, 35, 25, 49, 59, 4, 10, 26, 13, 9, 0, 50, 50, 18, 60, 47, 55, 42, 50, 32, 3, 49, 7, 44, 56, 35, 42, 60, 50, 7, 50, 48, 50, 50, 58, 4, 22, 32, 55, 8, 0, 39, 39, 50, 31, 22, 56, 47, 19, 32, 22, 25, 23, 7, 22, 60, 50, 21, 43, 34, 57, 50, 3, 22, 42, 9, 7, 20, 22, 37, 42, 41, 57, 53, 6, 9, 42, 58, 0, 7, 56, 8, 32, 50, 44, 47, 5, 19, 51, 18, 47, 28, 37, 52, 42, 13, 4, 39, 5, 57, 23, 42, 19, 9, 44, 50, 37, 50, 46, 42, 26, 34, 7, 17, 50, 6, 7, 33, 39, 41, 29, 21, 47, 47, 50, 50, 13, 10, 40, 8, 47, 13, 45, 55, 35, 17, 7, 21, 24, 24, 7, 44, 41, 42, 2, 33, 52, 50, 10, 50, 34, 8, 50, 51, 7, 50, 50, 51, 31, 7, 5, 23, 3, 34, 50, 47, 57, 61, 22, 32, 38, 33, 3, 50, 50, 18, 21, 58, 4, 22, 49, 7, 39, 37, 22, 12, 17, 36, 22, 48, 22, 13, 33, 14, 7, 7, 53, 43, 52, 53, 3, 5, 4, 21, 11, 42, 23, 14, 14, 5, 52, 39, 8, 4, 22, 26, 50, 40, 27, 17, 16, 4, 4, 11, 59, 4, 35, 47, 22, 4, 7, 50, 22, 26, 21, 4, 6, 14, 0, 0, 41, 50, 50, 23, 8, 56, 22, 26, 55, 49, 22, 42, 5, 9, 28, 35, 7, 50, 7, 20, 14, 8, 5, 13, 24, 46, 25, 42, 7, 24, 22, 20, 4, 0, 26, 27, 11, 7, 22, 23, 50, 32, 52, 42, 4, 39, 14, 24, 1, 4, 2, 39, 25, 48, 47, 7, 60, 31, 60, 36, 56, 6, 17, 28, 41, 19, 42, 26, 31, 18, 27, 39, 39, 20, 50, 23, 41, 5, 30, 55, 50, 43, 35, 3, 23, 9, 60, 0, 24, 17, 50, 46, 57, 7, 30, 15, 11, 4, 13, 38, 17, 37, 26, 18, 44, 61, 7, 32, 54, 50, 48, 3, 52, 22, 18, 53, 36, 11, 52, 12, 6, 61, 35, 28, 17, 40, 50, 1, 43, 32, 20, 7, 42, 10, 47, 40, 19, 1, 17, 22, 56, 46, 59, 4, 42, 50, 23, 23, 7, 10, 7, 40, 19, 24, 28, 7, 39, 11, 11, 25, 14, 7, 39, 42, 40, 23, 22, 47, 61, 54, 19, 21, 22, 50, 50, 28, 50, 42, 47, 25, 44, 1, 35, 29, 7, 7, 60, 7, 49, 7, 59, 42, 54, 53, 49, 35, 57, 26, 4, 42, 50, 12, 21, 43, 60, 4, 10, 54, 39, 20, 11, 50, 1, 28, 1, 4, 19, 29, 0, 58, 21, 41, 37, 7, 60, 22, 47, 49, 35, 13, 33, 22, 47, 34, 42, 41, 2, 9, 1, 7, 45, 25, 55, 7, 51, 43, 2, 39, 34, 6, 52, 7, 0, 14, 55, 54, 7, 34, 7, 32, 8, 38, 16, 61, 50, 7, 4, 17, 45, 43, 29, 55, 4, 47, 7, 36, 31, 50, 4, 28, 10, 37, 23, 18, 46, 0, 8, 50, 3, 42, 46, 42, 27, 28, 40, 42, 24, 22, 43, 41, 48, 0, 50, 49, 33, 5, 45, 41, 7, 20, 22, 22, 22, 10, 42, 12, 22, 1, 22, 50, 22, 11, 21, 7, 23, 21, 53, 28, 56, 50, 22, 42, 60, 9, 61, 60, 55, 43, 51, 58, 22, 19, 5, 7, 13, 3, 2, 3, 51, 22, 22, 50, 17, 40, 54, 14, 11, 20, 32, 40, 19, 4, 22, 13, 1, 45, 7, 9, 54, 60, 58, 61, 18, 39, 8, 42, 24, 4, 52, 13, 32, 41, 36, 7, 24, 14, 51, 23, 9, 25, 60, 7, 50, 43, 19, 55, 22, 10, 17, 22, 1, 47, 50, 59, 50, 30, 42, 55, 47, 20, 20, 41, 53, 19, 42, 3, 50, 42, 22, 47, 50, 7, 43, 60, 26, 50, 4, 3, 5, 31, 51, 59, 7, 0, 47, 11, 50, 43, 20, 42, 17, 21, 51, 32, 50, 18, 3, 36, 42, 49, 50, 41, 47, 27, 47, 50, 36, 23, 10, 39, 32, 50, 46, 50, 11, 18, 17, 27, 43, 44, 4, 23, 50, 8, 60, 42, 49, 37, 32, 3, 29, 10, 43, 50, 17, 53, 59, 7, 27, 5, 4, 56, 29, 7, 3, 21, 6, 27, 47, 43, 49, 30, 59, 33, 15, 21, 59, 8, 7, 22, 7, 42, 28, 26, 38, 61, 50, 50, 46, 14, 19, 1, 61, 42, 42, 52, 25, 4, 50, 47, 7, 46, 55, 52, 22, 50, 8, 50, 11, 7, 23, 50, 12, 7, 50, 50, 32, 7, 3, 58, 7, 22, 54, 21, 50, 3, 47, 35, 17, 43, 46, 14, 22, 61, 47, 18, 33, 3, 50, 50, 5, 14, 16, 60, 22, 60, 3, 5, 16, 2, 22, 60, 29, 22, 42, 19, 61, 23, 52, 50, 0, 11, 14, 30, 9, 2, 22, 50, 50, 55, 45, 17, 11, 3, 42, 37, 22, 47, 3, 54, 15, 30, 50, 45, 22, 12, 50, 41, 18, 60, 15, 40, 42, 13, 40, 8, 8, 7, 42, 5, 55, 50, 0, 14, 47, 19, 41, 44, 50, 38, 7, 6, 22, 4, 20, 7, 13, 26, 26, 48, 35, 3, 50, 5, 25, 4, 54, 57, 30, 22, 47, 0, 54, 9, 14, 50, 50, 29, 27, 47, 50, 4, 39, 25, 13, 15, 60, 42, 53, 22, 17, 50, 50, 46, 39, 54, 9, 46, 53, 4, 24, 17, 7, 42, 58, 7, 33, 32, 59, 4, 50, 45, 32, 50, 7, 58, 22, 47, 54, 59, 3, 42, 30, 17, 50, 23, 28, 23, 39, 59, 58, 19, 7, 22, 31, 16, 22, 8, 9, 25, 29, 22, 7, 40, 61, 22, 54, 9, 22, 44, 22, 53, 14, 1, 22, 15, 42, 7, 53, 11, 51, 61, 51, 32, 4, 36, 23, 22, 49, 15, 38, 48, 7, 50, 61, 50, 50, 49, 3, 54, 27, 50, 50, 0, 7, 20, 45, 0, 7, 2, 45, 53, 47, 6, 9, 22, 42, 57, 53, 4, 14, 30, 16, 7, 50, 27, 23, 0, 19, 36, 48, 57, 22, 50, 47, 17, 40, 47, 6, 51, 60, 32, 50, 23, 40, 1, 44, 4, 29, 7, 52, 7, 30, 32, 50, 7, 27, 54, 22, 47, 40, 19, 38, 60, 50, 54, 32, 41, 22, 22, 3, 23, 2, 44, 18, 7, 43, 42, 2, 10, 3, 0, 22, 59, 37, 30, 5, 22, 34, 42, 50, 30, 22, 44, 47, 38, 60, 13, 41, 58, 13, 50, 42, 4, 55, 23, 29, 7, 13, 50, 22, 19, 39, 47, 9, 41, 7, 32, 47, 50, 23, 25, 7, 22, 26, 7, 56, 22, 22, 22, 22, 20, 22, 50, 3, 7, 42, 50, 0, 39, 54, 47, 55, 50, 7, 13, 7, 7, 25, 26, 48, 25, 3, 59, 4, 21, 28, 5, 45, 4, 21, 53, 50, 33, 31, 50, 59, 50, 0, 22, 50, 51, 50, 25, 50, 22, 40, 7, 42, 23, 0, 1, 42, 10, 9, 13, 47, 40, 55, 28, 50, 49, 46, 38, 16, 37, 16, 21, 10, 34, 50, 28, 57, 30, 8, 10, 57, 23, 33, 13, 32, 13, 38, 46, 12, 11, 7, 42, 51, 60, 5, 50, 21, 0, 39, 34, 35, 15, 30, 47, 3, 46, 4, 41, 41, 16, 61, 37, 16, 3, 50, 5, 10, 14, 7, 7, 19, 30, 47, 51, 30, 13, 22, 28, 54, 50, 22, 24, 5, 32, 47, 51, 23, 0, 0, 56, 22, 30, 29, 61, 13, 47, 42, 17, 7, 50, 8, 22, 31, 26, 25, 50, 38, 20, 3, 51, 50, 42, 42, 50, 50, 19, 42, 59, 41, 60, 47, 0, 7, 50, 57, 7, 50, 43, 30, 11, 4, 4, 34, 34, 42, 23, 22, 22, 22, 18, 27, 41, 36, 59, 42, 59, 7, 60, 30, 47, 8, 0, 58, 51, 22, 20, 47, 27, 44, 42, 4, 25, 23, 3, 22, 26, 23, 56, 22, 4, 47, 7, 42, 46, 5, 11, 31, 7, 7, 30, 27, 17, 47, 61, 47, 4, 47, 4, 23, 50, 49, 43, 10, 50, 50, 28, 42, 53, 45, 20, 47, 7, 30, 60, 14, 20, 45, 23, 34, 19, 32, 7, 12, 55, 21, 42, 22, 22, 60, 15, 7, 50, 40, 59, 28, 6, 58, 4, 19, 49, 57, 15, 7, 59, 50, 47, 56, 12, 42, 7, 14, 4, 50, 14, 21, 10, 57, 50, 10, 23, 14, 0, 40, 7, 35, 47, 24, 42, 13, 22, 26, 47, 2, 23, 42, 26, 42, 14, 50, 46, 51, 3, 7, 32, 26, 56, 51, 49, 22, 3, 5, 23, 10, 28, 34, 51, 53, 50, 4, 9, 51, 27, 0, 15, 42, 56, 27, 51, 13, 50, 19, 11, 7, 7, 51, 7, 21, 9, 58, 44, 50, 50, 42, 34, 49, 23, 7, 6, 44, 48, 50, 45, 12, 30, 56, 28, 5, 54, 7, 22, 13, 50, 44, 2, 50, 61, 13, 22, 5, 17, 56, 42, 34, 25, 24, 46, 18, 52, 3, 23, 24, 39, 7, 15, 30, 60, 34, 60, 50, 40, 60, 32, 23, 42, 9, 23, 5, 51, 22, 60, 11, 45, 35, 34, 42, 25, 34, 6, 23, 48, 4, 45, 7, 29, 52, 34, 16, 7, 50, 51, 48, 61, 35, 10, 45, 42, 4, 18, 42, 49, 26, 7, 22, 0, 17, 60, 12, 45, 0, 46, 21, 7, 40, 3, 13, 4, 28, 2, 28, 42, 42, 28, 7, 13, 6, 50, 22, 12, 39, 40, 8, 22, 50, 11, 17, 38, 53, 22, 50, 57, 5, 22, 15, 34, 26, 46, 55, 43, 47, 8, 23, 50, 50, 50, 45, 50, 24, 2, 7, 50, 50, 50, 18, 41, 61, 19, 40, 58, 21, 47, 21, 37, 46, 57, 50, 35, 42, 0, 22, 22, 27, 57, 36, 50, 1, 14, 38, 50, 26, 56, 1, 55, 54, 50, 22, 20, 51, 37, 51, 34, 56, 47, 5, 3, 7, 17, 47, 8, 60, 22, 0, 59, 2, 37, 9, 55, 54, 50, 20, 55, 0, 0, 16, 13, 15, 13, 50, 48, 24, 42, 29, 2, 53, 7, 4, 50, 43, 12, 27, 51, 23, 10, 4, 55, 47, 10, 48, 23, 32, 59, 23, 7, 22, 7, 7, 50, 36, 47, 54, 32, 13, 50, 15, 7, 4, 7, 7, 19, 22, 28, 56, 4, 7, 45, 50, 11, 42, 24, 33, 39, 50, 42, 46, 25, 22, 20, 28, 8, 0, 7, 8, 22, 7, 43, 7, 4, 32, 50, 50, 61, 46, 56, 51, 50, 25, 47, 42, 47, 45, 39, 23, 50, 49, 25, 0, 55, 18, 26, 6, 58, 56, 7, 50, 42, 42, 24, 3, 22, 41, 28, 50, 50, 38, 39, 22, 48, 35, 22, 14, 7, 7, 50, 41, 20, 4, 20, 58, 23, 25, 8, 39, 16, 42, 50, 22, 42, 7, 47, 15, 47, 7, 22, 52, 60, 25, 61, 50, 21, 57, 19, 47, 38, 50, 53, 61, 58, 23, 31, 51, 32, 7, 29, 42, 42, 25, 4, 37, 50, 0, 13, 55, 7, 22, 1, 1, 38, 51, 38, 47, 55, 7, 23, 42, 7, 14, 58, 61, 50, 6, 1, 5, 56, 22, 11, 53, 22, 48, 15, 7, 41, 22, 40, 60, 9, 29, 7, 41, 3, 52, 7, 59, 29, 7, 30, 47, 50, 43, 57, 24, 23, 9, 17, 20, 49, 13, 31, 40, 46, 50, 1, 5, 46, 9, 3, 50, 60, 9, 51, 26, 50, 50, 2, 16, 9, 50, 7, 28, 36, 4, 56, 51, 23, 50, 22, 40, 32, 7, 24, 28, 22, 14, 22, 53, 50, 9, 52, 1, 50, 2, 47, 17, 22, 27, 18, 34, 39, 32, 54, 16, 3, 50, 0, 3, 47, 26, 47, 43, 4, 23, 19, 42, 22, 55, 14, 16, 52, 60, 19, 23, 56, 44, 7, 22, 7, 24, 4, 34, 5, 34, 23, 37, 6, 7, 8, 5, 4, 5, 10, 12, 60, 8, 48, 39, 55, 3, 22, 32, 22, 22, 52, 22, 50, 61, 26, 22, 31, 16, 48, 19, 9, 31, 54, 10, 13, 18, 42, 15, 7, 53, 50, 47, 30, 42, 44, 50, 59, 25, 5, 22, 47, 40, 33, 56, 4, 23, 13, 60, 13, 51, 7, 19, 9, 9, 4, 10, 22, 42, 48, 9, 19, 22, 50, 39, 3, 50, 14, 17, 31, 47, 6, 18, 59, 50, 22, 11, 32, 56, 2, 1, 33, 47, 50, 55, 13, 15, 21, 40, 31, 17, 20, 51, 7, 38, 49, 46, 58, 4, 11, 60, 35, 51, 46, 42, 31, 50, 2, 52, 53, 23, 50, 42, 28, 27, 27, 24, 59, 55, 11, 39, 6, 1, 50, 30, 48, 46, 54, 1, 23, 43, 25, 23, 24, 50, 4, 16, 42, 7, 55, 50, 44, 22, 1, 7, 20, 22, 8, 0, 50, 20, 4, 7, 42, 23, 7, 44, 0, 4, 22, 51, 50, 0, 19, 49, 47, 50, 23, 54, 1, 32, 42, 50, 14, 48, 1, 4, 59, 42, 47, 31, 42, 5, 50, 42, 21, 53, 44, 38, 39, 26, 50, 7, 45, 4, 42, 30, 52, 28, 2, 60, 50, 32, 4, 12, 44, 23, 11, 50, 12, 50, 42, 50, 10, 35, 33, 50, 36, 4, 7, 22, 35, 32, 47, 61, 25, 7, 28, 21, 0, 59, 4, 14, 28, 10, 49, 4, 8, 4, 23, 7, 12, 42, 47, 55, 53, 47, 29, 51, 50, 53, 57, 33, 41, 11, 25, 0, 37, 16, 25, 7, 42, 29, 11, 45, 50, 60, 28, 46, 14, 53, 23, 8, 6, 7, 59, 32, 8, 55, 28, 50, 53, 4, 47, 47, 22, 19, 47, 1, 4, 11, 7, 22, 51, 34, 43, 50, 22, 50, 43, 50, 32, 10, 32, 22, 21, 44, 39, 21, 51, 22, 11, 17, 20, 28, 4, 29, 22, 50, 50, 55, 49, 59, 47, 60, 48, 32, 7, 47, 53, 7, 12, 7, 32, 46, 43, 22, 42, 35, 18, 7, 61, 39, 38, 15, 50, 26, 7, 50, 32, 32, 50, 25, 4, 38, 51, 9, 39, 57, 32, 50, 42, 50, 40, 41, 21, 1, 42, 35, 40, 56, 22, 44, 60, 22, 31, 22, 42, 7, 50, 31, 10, 31, 4, 27, 51, 7, 7, 52, 47, 4, 1, 24, 59, 19, 8, 51, 50, 22, 14, 25, 23, 15, 9, 28, 4, 8, 12, 18, 47, 23, 54, 26, 14, 42, 14, 33, 24, 7, 50, 7, 37, 56, 22, 35, 23, 58, 60, 22, 47, 22, 45, 27, 46, 16, 34, 2, 50, 38, 40, 4, 51, 47, 60, 21, 52, 60, 31, 55, 36, 57, 42, 30, 3, 41, 22, 52, 50, 36, 42, 4, 26, 3, 39, 51, 22, 60, 54, 41, 58, 7, 22, 16, 50, 51, 31, 39, 32, 9, 39, 4, 50, 22, 39, 40, 2, 46, 51, 7, 29, 0, 7, 50, 13, 50, 50, 26, 16, 4, 15, 5, 44, 15, 54, 1, 43, 46, 47, 42, 21, 46, 4, 42, 46, 1, 27, 52, 55, 22, 7, 48, 47, 45, 47, 35, 57, 21, 12, 50, 46, 58, 26, 39, 54, 41, 42, 12, 4, 32, 32, 50, 25, 58, 7, 5, 16, 51, 51, 7, 6, 5, 15, 40, 2, 50, 7, 1, 44, 7, 53, 9, 42, 9, 7, 22, 15, 20, 11, 20, 1, 8, 41, 50, 4, 36, 27, 36, 7, 20, 8, 9, 18, 37, 23, 54, 8, 29, 22, 42, 55, 4, 40, 9, 54, 36, 44, 5, 40, 18, 56, 4, 40, 22, 32, 22, 7, 22, 51, 8, 50, 55, 50, 21, 11, 8, 47, 13, 30, 23, 7, 9, 6, 47, 21, 50, 4, 47, 3, 32, 50, 47, 38, 49, 4, 25, 50, 55, 47, 16, 17, 5, 32, 59, 38, 57, 39, 51, 60, 47, 6, 50, 50, 4, 3, 4, 33, 50, 41, 20, 50, 50, 38, 2, 9, 8, 21, 56, 10, 5, 44, 37, 28, 29, 13, 50, 33, 60, 47, 40, 11, 42, 50, 9, 10, 60, 50, 31, 20, 23, 42, 24, 21, 47, 7, 7, 50, 36, 14, 49, 43, 25, 50, 32, 23, 33, 7, 22, 32, 7, 17, 61, 7, 26, 35, 23, 20, 7, 38, 22, 0, 54, 4, 41, 7, 23, 6, 31, 53, 0, 42, 19, 35, 37, 26, 34, 42, 35, 10, 21, 7, 8, 21, 55, 28, 45, 38, 26, 25, 1, 9, 22, 16, 50, 7, 50, 50, 50, 20, 42, 20, 47, 57, 4, 8, 22, 22, 50, 2, 61, 4, 22, 24, 6, 7, 22, 7, 7, 32, 55, 5, 37, 7, 36, 42, 23, 13, 29, 36, 2, 23, 37, 4, 48, 6, 18, 50, 57, 8, 38, 17, 59, 61, 53, 3, 60, 27, 22, 22, 44, 19, 31, 0, 55, 10, 15, 7, 42, 4, 50, 12, 32, 22, 59, 50, 47, 22, 12, 42, 18, 35, 22, 42, 1, 11, 22, 3, 55, 28, 47, 60, 11, 35, 50, 22, 50, 21, 36, 28, 17, 50, 29, 0, 22, 50, 8, 13, 20, 22, 33, 11, 7, 22, 3, 7, 29, 46, 21, 39, 41, 7, 13, 59, 22, 47, 16, 29, 42, 10, 7, 29, 0, 51, 27, 22, 20, 42, 33, 23, 5, 50, 5, 7, 7, 29, 9, 3, 14, 0, 20, 34, 50, 50, 48, 4, 57, 56, 42, 4, 50, 11, 19, 50, 46, 17, 0, 24, 29, 32, 40, 58, 15, 50, 22, 24, 42, 31, 4, 43, 17, 47, 56, 18, 25, 50, 53, 1, 23, 22, 50, 4, 10, 18, 25, 3, 50, 50, 40, 52, 3, 50, 47, 9, 50, 50, 60, 60, 50, 58, 57, 0, 4, 47, 31, 10, 50, 44, 14, 7, 27, 7, 45, 2, 33, 23, 5, 54, 35, 44, 58, 43, 22, 23, 4, 44, 50, 25, 6, 22, 44, 53, 7, 58, 57, 50, 7, 50, 22, 23, 50, 4, 59, 51, 57, 54, 11, 10, 22, 54, 50, 40, 7, 12, 50, 40, 50, 47, 35, 51, 9, 46, 18, 38, 12, 20, 7, 20, 17, 51, 3, 7, 33, 0, 2, 21, 61, 32, 7, 3, 30, 0, 44, 11, 57, 17, 0, 7, 3, 50, 4, 60, 25, 54, 22, 22, 8, 7, 52, 51, 7, 6, 50, 21, 4, 18, 53, 13, 1, 33, 33, 12, 20, 33, 28, 22, 25, 22, 13, 5, 44, 41, 8, 51, 56, 51, 53, 58, 33, 56, 51, 1, 23, 24, 47, 35, 33, 12, 47, 37, 51, 2, 34, 23, 29, 50, 45, 51, 22, 21, 60, 50, 44, 9, 47, 51, 12, 37, 0, 58, 31, 50, 56, 47, 36, 59, 61, 42, 47, 3, 1, 13, 50, 56, 7, 8, 17, 45, 51, 7, 5, 21, 45, 10, 33, 7, 7, 5, 10, 7, 42, 50, 7, 53, 50, 46, 7, 50, 8, 23, 9, 5, 14, 3, 50, 22, 21, 47, 2, 17, 22, 17, 50, 22, 51, 23, 29, 38, 48, 22, 54, 7, 16, 23, 39, 4, 48, 49, 7, 22, 44, 50, 60, 60, 7, 22, 44, 7, 50, 3, 46, 47, 22, 40, 5, 35, 26, 30, 20, 27, 22, 13, 1, 19, 2, 44, 18, 9, 45, 59, 50, 7, 22, 37, 3, 23, 49, 37, 9, 21, 51, 54, 50, 21, 47, 1, 48, 24, 12, 37, 0, 3, 7, 41, 4, 24, 47, 22, 22, 30, 50, 34, 0, 30, 57, 7, 42, 42, 36, 54, 22, 2, 20, 60, 7, 23, 5, 29, 9, 25, 45, 23, 48, 23, 10, 1, 7, 12, 28, 1, 43, 4, 45, 7, 37, 7, 48, 28, 21, 20, 7, 7, 47, 23, 18, 20, 52, 23, 47, 2, 36, 11, 46, 50, 60, 9, 54, 54, 42, 17, 19, 22, 18, 30, 50, 50, 7, 46, 12, 40, 50, 1, 53, 16, 0, 0, 9, 7, 13, 57, 50, 10, 26, 44, 3, 31, 51, 9, 6, 28, 39, 50, 60, 11, 8, 1, 50, 32, 17, 4, 59, 29, 32, 6, 2, 41, 50, 1, 56, 11, 22, 31, 51, 4, 54, 41, 20, 39, 41, 20, 27, 16, 4, 60, 5, 11, 7, 19, 17, 38, 50, 42, 56, 22, 27, 17, 32, 56, 7, 60, 0, 50, 41, 50, 18, 18, 31, 23, 30, 33, 34, 19, 32, 53, 39, 22, 48, 45, 25, 52, 51, 50, 25, 7, 60, 9, 50, 7, 14, 20, 58, 38, 7, 10, 44, 53, 7, 33, 23, 42, 7, 43, 57, 26, 59, 6, 8, 8, 7, 23, 22, 51, 11, 57, 10, 33, 41, 0, 50, 58, 54, 22, 59, 47, 47, 4, 50, 50, 56, 10, 4, 7, 9, 26, 51, 7, 54, 47, 10, 14, 27, 18, 59, 50, 15, 14, 3, 25, 22, 31, 60, 31, 47, 35, 15, 3, 16, 47, 21, 11, 4, 22, 11, 23, 59, 8, 47, 46, 4, 50, 41, 25, 23, 50, 31, 42, 50, 51, 50, 57, 15, 7, 26, 5, 7, 39, 41, 60, 52, 29, 42, 37, 46, 38, 22, 15, 28, 46, 44, 39, 8, 50, 7, 11, 59, 25, 38, 13, 7, 56, 43, 50, 52, 15, 59, 25, 50, 23, 31, 7, 50, 27, 50, 32, 23, 36, 53, 49, 23, 50, 23, 42, 13, 35, 48, 26, 6, 10, 23, 47, 46, 0, 4, 4, 41, 13, 50, 23, 22, 42, 42, 31, 26, 50, 5, 32, 35, 60, 55, 22, 45, 44, 7, 31, 7, 55, 59, 4, 12, 13, 43, 58, 18, 23, 22, 13, 60, 15, 22, 42, 7, 50, 50, 26, 24, 17, 10, 25, 28, 27, 4, 50, 4, 29, 25, 19, 47, 7, 7, 3, 26, 53, 5, 47, 41, 12, 7, 50, 50, 28, 1, 34, 7, 51, 25, 50, 50, 19, 21, 50, 15, 0, 55, 11, 4, 7, 22, 30, 0, 1, 47, 7, 34, 0, 50, 15, 50, 50, 13, 22, 21, 40, 22, 44, 59, 50, 16, 60, 37, 50, 4, 7, 55, 41, 61, 3, 32, 34, 50, 38, 43, 50, 11, 43, 10, 39, 56, 0, 10, 38, 28, 4, 41, 57, 36, 18, 4, 8, 14, 9, 50, 10, 5, 50, 50, 41, 58, 7, 22, 4, 60, 49, 42, 41, 41, 19, 39, 50, 9, 52, 50, 27, 10, 60, 47, 29, 56, 46, 22, 8, 42, 54, 51, 22, 51, 50, 34, 55, 40, 58, 22, 5, 5, 50, 26, 7, 12, 23, 19, 34, 47, 50, 13, 15, 34, 60, 20, 51, 43, 42, 8, 20, 7, 22, 3, 8, 51, 3, 24, 50, 33, 3, 4, 50, 34, 22, 60, 56, 38, 38, 39, 50, 12, 49, 50, 22, 60, 50, 27, 61, 23, 13, 38, 32, 25, 35, 42, 8, 50, 22, 46, 50, 7, 50, 6, 48, 49, 48, 50, 42, 60, 50, 21, 60, 7, 44, 60, 54, 26, 22, 22, 34, 60, 7, 15, 4, 8, 42, 21, 25, 38, 50, 42, 25, 11, 50, 50, 7, 10, 8, 17, 1, 57, 41, 13, 43, 58, 21, 39, 41, 39, 35, 50, 9, 58, 4, 4, 50, 50, 34, 4, 50, 42, 22, 42, 16, 17, 7, 16, 51, 61, 50, 41, 25, 39, 40, 50, 32, 59, 3, 50, 42, 37, 50, 15, 2, 22, 6, 50, 0, 14, 7, 13, 21, 56, 50, 18, 11, 46, 7, 50, 56, 57, 19, 25, 19, 10, 56, 7, 50, 54, 22, 56, 16, 56, 43, 50, 33, 52, 50, 25, 37, 37, 52, 50, 8, 44, 20, 16, 8, 42, 17, 4, 47, 25, 31, 8, 22, 4, 50, 4, 42, 29, 34, 2, 47, 38, 29, 45, 7, 56, 9, 1, 23, 61, 56, 17, 45, 56, 50, 55, 50, 24, 7, 0, 16, 35, 52, 8, 7, 6, 42, 50, 16, 60, 50, 7, 9, 22, 43, 21, 12, 10, 46, 7, 50, 14, 19, 29, 7, 17, 7, 22, 50, 10, 23, 21, 22, 39, 11, 11, 50, 22, 53, 23, 6, 52, 7, 50, 60, 18, 57, 12, 47, 6, 5, 19, 3, 14, 32, 50, 23, 27, 28, 50, 47, 17, 60, 42, 7, 54, 7, 8, 47, 33, 13, 5, 46, 25, 35, 30, 7, 20, 7, 47, 22, 42, 52, 50, 28, 48, 24, 54, 15, 1, 7, 42, 22, 49, 44, 22, 43, 55, 24, 17, 54, 47, 34, 39, 51, 17, 45, 27, 9, 40, 22, 14, 17, 14, 50, 42, 19, 53, 38, 49, 44, 22, 58, 34, 20, 14, 9, 47, 50, 25, 11, 42, 19, 42, 59, 45, 42, 60, 39, 42, 50, 7, 39, 31, 52, 56, 8, 41, 31, 36, 12, 22, 52, 16, 47, 8, 12, 39, 60, 18, 45, 19, 25, 23, 16, 20, 4, 28, 50, 27, 30, 53, 51, 2, 7, 34, 17, 48, 7, 50, 18, 22, 22, 36, 50, 4, 13, 4, 42, 61, 7, 33, 22, 36, 61, 44, 54, 0, 22, 59, 22, 11, 29, 40, 18, 23, 3, 19, 7, 51, 29, 46, 50, 4, 10, 7, 32, 54, 51, 5, 22, 6, 22, 40, 5, 43, 4, 60, 2, 60, 42, 8, 42, 22, 40, 5, 6, 47, 46, 14, 14, 57, 4, 8, 13, 21, 13, 22, 53, 20, 4, 4, 23, 24, 22, 31, 42, 0, 42, 4, 50, 58, 12, 1, 20, 39, 7, 50, 50, 26, 8, 49, 45, 15, 7, 30, 45, 58, 50, 44, 25, 5, 10, 7, 37, 59, 7, 50, 45, 13, 42, 50, 36, 47, 60, 5, 42, 32, 41, 0, 17, 10, 6, 12, 50, 34, 38, 59, 37, 27, 50, 24, 60, 8, 47, 33, 50, 19, 7, 36, 56, 5, 8, 8, 9, 50, 61, 32, 37, 60, 48, 30, 9, 59, 25, 32, 4, 50, 47, 37, 60, 30, 32, 17, 42, 33, 45, 17, 36, 50, 51, 3, 3, 13, 28, 15, 50, 51, 52, 30, 60, 38, 8, 15, 43, 22, 23, 3, 23, 42, 50, 18, 4, 35, 7, 19, 46, 17, 42, 18, 50, 39, 57, 7, 15, 16, 58, 4, 60, 55, 50, 17, 46, 31, 4, 23, 50, 18, 47, 20, 42, 18, 6, 47, 50, 51, 17, 38, 12, 27, 5, 61, 35, 50, 8, 50, 43, 26, 40, 4, 25, 22, 24, 50, 50, 50, 11, 56, 50, 5, 39, 52, 0, 22, 50, 47, 4, 50, 28, 46, 43, 24, 50, 23, 3, 38, 1, 42, 6, 50, 30, 17, 46, 26, 50, 32, 24, 19, 33, 23, 55, 50, 14, 11, 29, 50, 14, 5, 60, 14, 8, 29, 5, 22, 22, 14, 50, 17, 47, 42, 51, 29, 60, 12, 30, 18, 57, 59, 17, 20, 22, 47, 51, 4, 31, 11, 9, 52, 3, 22, 5, 0, 22, 17, 50, 3, 61, 2, 19, 16, 7, 40, 60, 8, 12, 0, 36, 60, 26, 0, 51, 56, 50, 23, 19, 51, 14, 35, 22, 50, 18, 7, 49, 28, 13, 20, 19, 26, 0, 0, 39, 57, 50, 50, 5, 23, 42, 61, 54, 4, 32, 40, 16, 38, 60, 24, 4, 33, 14, 45, 41, 4, 49, 50, 3, 48, 50, 4, 50, 22, 58, 5, 11, 47, 22, 1, 25, 0, 13, 57, 41, 39, 50, 28, 35, 40, 7, 24, 57, 54, 60, 50, 51, 8, 2, 7, 41, 50, 3, 26, 50, 15, 36, 22, 41, 9, 50, 23, 37, 42, 7, 4, 41, 42, 14, 4, 60, 32, 46, 41, 41, 22, 46, 7, 15, 0, 4, 27, 55, 32, 1, 8, 22, 48, 56, 52, 16, 56, 1, 0, 50, 8, 50, 50, 13, 50, 50, 39, 39, 20, 23, 23, 36, 50, 22, 3, 2, 56, 42, 51, 53, 53, 47, 34, 49, 3, 52, 11, 25, 15, 50, 50, 7, 19, 49, 37, 42, 52, 47, 11, 60, 32, 50, 16, 10, 13, 22, 22, 23, 18, 47, 45, 45, 31, 22, 4, 40, 60, 59, 0, 60, 3, 0, 50, 59, 19, 3, 1, 58, 0, 9, 54, 4, 11, 15, 7, 10, 7, 53, 22, 50, 50, 9, 21, 61, 4, 39, 22, 50, 49, 19, 8, 45, 23, 4, 57, 55, 34, 26, 7, 7, 2, 22, 7, 7, 50, 24, 22, 7, 50, 51, 4, 44, 3, 52, 20, 7, 39, 15, 57, 7, 47, 27, 1, 60, 50, 0, 50, 7, 37, 32, 9, 9, 42, 17, 4, 5, 8, 0, 50, 7, 9, 1, 17, 50, 13, 8, 32, 50, 6, 52, 20, 13, 56, 22, 8, 9, 28, 22, 7, 20, 50, 42, 7, 50, 53, 47, 29, 4, 22, 22, 22, 22, 4, 40, 5, 25, 50, 9, 22, 26, 5, 1, 19, 9, 41, 11, 31, 15, 56, 4, 20, 2, 50, 50, 17, 7, 41, 56, 32, 22, 42, 22, 49, 12, 50, 9, 29, 46, 22, 50, 50, 22, 11, 54, 40, 50, 46, 18, 42, 22, 31, 46, 39, 46, 31, 55, 14, 7, 7, 41, 40, 47, 8, 3, 34, 49, 53, 50, 57, 26, 25, 14, 50, 16, 22, 7, 50, 4, 6, 0, 51, 61, 41, 61, 23, 51, 52, 47, 48, 13, 47, 42, 22, 34, 46, 25, 8, 24, 7, 7, 5, 23, 7, 46, 23, 50, 46, 50, 58, 23, 50, 50, 3, 31, 46, 7, 31, 47, 50, 22, 5, 57, 57, 45, 42, 43, 51, 59, 7, 20, 13, 22, 52, 50, 34, 8, 36, 53, 13, 47, 7, 12, 39, 27, 15, 35, 47, 7, 20, 26, 16, 7, 47, 43, 28, 48, 20, 50, 30, 1, 23, 3, 22, 55, 18, 60, 61, 34, 0, 30, 22, 7, 20, 16, 50, 15, 27, 7, 31, 22, 13, 42, 45, 14, 30, 50, 50, 33, 42, 14, 33, 58, 1, 47, 28, 9, 4, 3, 41, 47, 54, 4, 2, 52, 4, 4, 23, 0, 38, 45, 40, 39, 52, 0, 0, 16, 15, 8, 4, 51, 32, 56, 51, 7, 22, 32, 4, 34, 18, 0, 30, 30, 46, 50, 22, 24, 51, 54, 43, 47, 31, 30, 32, 9, 3, 1, 61, 50, 45, 20, 5, 7, 8, 52, 8, 7, 19, 7, 4, 22, 24, 12, 0, 24, 14, 50, 40, 22, 45, 8, 4, 28, 3, 50, 0, 30, 50, 53, 8, 26, 23, 50, 7, 36, 0, 20, 7, 61, 42, 8, 54, 33, 23, 41, 46, 14, 14, 3, 42, 4, 17, 26, 48, 4, 2, 53, 2, 22, 23, 55, 34, 28, 7, 60, 7, 10, 60, 22, 22, 51, 7, 20, 17, 51, 56, 5, 5, 60, 41, 9, 47, 12, 22, 7, 12, 60, 7, 60, 28, 22, 60, 47, 49, 0, 16, 35, 22, 59, 48, 41, 38, 47, 6, 23, 7, 23, 22, 22, 7, 60, 50, 7, 60, 51, 7, 50, 53, 52, 42, 38, 43, 19, 30, 27, 33, 4, 50, 60, 15, 48, 8, 19, 30, 46, 7, 5, 44, 7, 7, 5, 44, 1, 47, 28, 35, 22, 30, 21, 57, 42, 53, 46, 22, 8, 60, 40, 38, 11, 32, 29, 11, 4, 54, 23, 46, 50, 44, 50, 51, 4, 21, 55, 2, 22, 17, 59, 22, 7, 57, 27, 3, 30, 34, 33, 7, 12, 7, 50, 50, 23, 47, 22, 7, 2, 37, 42, 45, 4, 53, 59, 50, 45, 60, 22, 35, 7, 0, 16, 4, 51, 60, 57, 7, 3, 23, 51, 61, 27, 45, 52, 33, 26, 22, 7, 5, 5, 25, 37, 21, 22, 7, 50, 14, 49, 5, 42, 60, 33, 33, 4, 30, 57, 32, 51, 42, 18, 53, 50, 40, 4, 38, 27, 54, 32, 34, 1, 59, 42, 42, 36, 47, 38, 18, 7, 8, 57, 60, 4, 47, 51, 57, 0, 41, 42, 50, 46, 30]\n",
            "[49, 4, 56, 7, 7, 60, 56, 20, 23, 32, 21, 33, 16, 50, 5, 60, 53, 26, 22, 60, 1, 50, 53, 24, 16, 50, 42, 33, 51, 22, 10, 2, 7, 50, 52, 26, 50, 51, 51, 7, 50, 50, 17, 52, 19, 2, 7, 50, 59, 44, 47, 50, 60, 12, 47, 7, 23, 50, 7, 4, 4, 10, 42, 42, 48, 52, 53, 7, 32, 47, 13, 18, 60, 55, 34, 20, 56, 23, 31, 24, 21, 7, 50, 50, 6, 48, 42, 31, 22, 31, 18, 5, 52, 23, 60, 11, 29, 38, 23, 7, 47, 50, 22, 59, 51, 22, 24, 24, 35, 46, 32, 47, 60, 35, 47, 22, 43, 42, 22, 19, 4, 36, 34, 7, 50, 46, 31, 28, 10, 4, 7, 32, 55, 56, 0, 60, 42, 50, 6, 1, 9, 5, 42, 20, 3, 50, 6, 0, 8, 61, 22, 47, 3, 7, 22, 48, 22, 0, 14, 40, 44, 7, 5, 50, 10, 22, 7, 50, 50, 39, 0, 22, 17, 59, 55, 41, 9, 50, 50, 50, 60, 42, 47, 29, 5, 4, 58, 22, 22, 7, 25, 50, 7, 22, 46, 22, 32, 47, 23, 7, 47, 4, 31, 1, 7, 25, 54, 50, 5, 50, 23, 22, 61, 7, 50, 61, 50, 50, 26, 30, 5, 7, 0, 35, 60, 26, 50, 22, 42, 3, 56, 5, 51, 4, 60, 36, 5, 32, 29, 22, 23, 7, 14, 52, 23, 0, 47, 22, 24, 50, 21, 25, 18, 59, 24, 7, 46, 32, 25, 9, 21, 54, 38, 44, 11, 42, 7, 1, 19, 7, 36, 11, 0, 50, 34, 3, 7, 24, 51, 3, 50, 7, 41, 57, 27, 17, 59, 30, 50, 7, 50, 37, 11, 28, 5, 26, 4, 26, 56, 13, 30, 59, 35, 42, 40, 39, 13, 23, 20, 38, 37, 31, 17, 47, 7, 33, 30, 47, 27, 47, 41, 39, 20, 53, 50, 50, 6, 7, 47, 5, 17, 9, 35, 4, 7, 50, 47, 59, 50, 50, 50, 59, 12, 21, 4, 48, 10, 32, 41, 23, 37, 10, 42, 15, 22, 52, 18, 47, 8, 52, 32, 40, 32, 6, 14, 32, 5, 39, 35, 37, 11, 1, 35, 0, 20, 22, 42, 50, 13, 32, 3, 27, 51, 59, 50, 44, 50, 39, 0, 7, 2, 22, 31, 22, 50, 15, 56, 36, 0, 23, 56, 0, 42, 59, 20, 35, 50, 56, 12, 21, 42, 42, 60, 3, 16, 56, 58, 21, 1, 29, 7, 10, 45, 40, 50, 58, 15, 7, 0, 56, 3, 50, 50, 52, 59, 50, 7, 22, 51, 21, 7, 23, 22, 48, 39, 13, 50, 51, 34, 47, 50, 36, 43, 5, 11, 15, 49, 8, 7, 27, 23, 34, 23, 53, 24, 40, 6, 9, 56, 7, 34, 47, 36, 49, 57, 25, 50, 33, 52, 5, 47, 45, 43, 36, 45, 1, 2, 24, 41, 50, 27, 47, 27, 7, 45, 19, 42, 34, 7, 54, 7, 46, 18, 42, 8, 36, 23, 10, 31, 45, 1, 5, 22, 2, 26, 17, 29, 57, 51, 29, 50, 11, 60, 4, 15, 19, 52, 7, 40, 50, 46, 19, 18, 38, 7, 46, 7, 4, 22, 24, 34, 37, 30, 50, 31, 22, 7, 42, 50, 5, 25, 50, 31, 15, 37, 30, 58, 26, 44, 58, 36, 17, 11, 50, 9, 24, 5, 22, 2, 22, 50, 23, 42, 43, 4, 31, 50, 55, 23, 22, 29, 42, 20, 50, 22, 21, 52, 61, 50, 34, 30, 40, 16, 7, 22, 0, 7]\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgmdVacmQGw8",
        "outputId": "6e822b77-62b1-435a-ff64-6bb4eb8d3f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(labels[0])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GrY0ZJs7Tswj",
        "outputId": "414da6cb-32ce-4814-91a2-26e3b2892d42"
      },
      "source": [
        "lr = 1e-5\r\n",
        "lr_decay_factor = 0.9\r\n",
        "lr_decay_every = 5\r\n",
        "weight_decay = 1e-4\r\n",
        "\r\n",
        "warm_up_epoch = 0\r\n",
        "early_stopping_patience = 10\r\n",
        "early_stopping_criteria = 'loss'\r\n",
        "best_epoch = 0 # Initialize\r\n",
        "\r\n",
        "training = {}\r\n",
        "validation = {}\r\n",
        "testing = {}\r\n",
        "training['accuracy'] = []\r\n",
        "training['loss'] = []\r\n",
        "validation['accuracy'] = []\r\n",
        "validation['loss'] = []\r\n",
        "testing['accuracy'] = []\r\n",
        "testing['loss'] = []\r\n",
        "\r\n",
        "for epoch in range(20):\r\n",
        "    model.train()\r\n",
        "    train_loss = 0\r\n",
        "    train_correct_items = 0\r\n",
        "    previous_epoch_timestamp = time()\r\n",
        "\r\n",
        "    if epoch % lr_decay_every == 0: # Update optimizer for every lr_decay_every epochs\r\n",
        "        if epoch != 0: # When it is the first epoch, disable the lr_decay_factor\r\n",
        "            lr *= lr_decay_factor\r\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\r\n",
        "\r\n",
        "    for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(train_loader):\r\n",
        "#         print('Finished batch:', i)\r\n",
        "        node_sets = node_sets.to(device)\r\n",
        "        neighbor_sets = neighbor_sets.to(device)\r\n",
        "        public_edge_masks = public_edge_masks.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\r\n",
        "        loss = criterion(prediction, labels).to(device)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        train_loss += loss.item()\r\n",
        "        train_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\r\n",
        "    train_accuracy = train_correct_items / len(dataset.train_dataset)\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    validation_loss = 0\r\n",
        "    validation_correct_items = 0\r\n",
        "    for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(validation_loader):\r\n",
        "        node_sets = node_sets.to(device)\r\n",
        "        neighbor_sets = neighbor_sets.to(device)\r\n",
        "        public_edge_masks = public_edge_masks.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        prediction = model(node_sets, neighbor_sets, public_edge_masks)\r\n",
        "        loss = criterion(prediction, labels).to(device)\r\n",
        "        validation_loss += loss.item()\r\n",
        "        validation_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\r\n",
        "    validation_accuracy = validation_correct_items / len(dataset.validation_dataset)\r\n",
        "\r\n",
        "#     model.eval()\r\n",
        "    # test_loss = 0\r\n",
        "    # test_correct_items = 0\r\n",
        "    # for i, (node_sets, neighbor_sets, public_edge_masks, labels) in enumerate(test_loader):\r\n",
        "    #     node_sets = node_sets.to(device)\r\n",
        "    #     neighbor_sets = neighbor_sets.to(device)\r\n",
        "    #     public_edge_masks = public_edge_masks.to(device)\r\n",
        "    #     labels = labels.to(device)\r\n",
        "    #     prediction = model(node_sets, neighbor_sets, public_edge_masks)\r\n",
        "    #     loss = criterion(prediction, labels).to(device)\r\n",
        "    #     test_loss += loss.item()\r\n",
        "    #     test_correct_items += (prediction.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\r\n",
        "    # test_accuracy = test_correct_items / len(dataset.test_dataset)\r\n",
        "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {validation_accuracy:.4f}, Time Used: {time()-previous_epoch_timestamp:.2f}s')\r\n",
        "    training['accuracy'].append(train_accuracy)\r\n",
        "    training['loss'].append(train_loss)\r\n",
        "    validation['accuracy'].append(validation_accuracy)\r\n",
        "    validation['loss'].append(validation_loss)\r\n",
        "    # testing['accuracy'].append(test_accuracy)\r\n",
        "    # testing['loss'].append(test_loss)\r\n",
        "\r\n",
        "    # add warmup mechanism for warm_up_epoch epochs\r\n",
        "    if epoch >= warm_up_epoch:\r\n",
        "        best_epoch = warm_up_epoch\r\n",
        "        # early stopping\r\n",
        "        if early_stopping_criteria == 'accuracy':\r\n",
        "            if validation['accuracy'][epoch] > validation['accuracy'][best_epoch]:\r\n",
        "                best_epoch = epoch\r\n",
        "            elif epoch >= best_epoch + early_stopping_patience:\r\n",
        "                print(f'Early stopping... (No further increase in validation accuracy) for consecutive {early_stopping_patience} epochs.')\r\n",
        "                break\r\n",
        "        if early_stopping_criteria == 'loss':\r\n",
        "            if validation['loss'][epoch] < validation['loss'][best_epoch]:\r\n",
        "                best_epoch = epoch\r\n",
        "            elif epoch >= best_epoch + early_stopping_patience:\r\n",
        "                print(f'Early stopping... (No further decrease in validation loss) for consecutive {early_stopping_patience} epochs.')\r\n",
        "                break\r\n",
        "    elif epoch + 1 == warm_up_epoch:\r\n",
        "        print('--- Warm up finished ---')\r\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At pad custom sequence\n",
            "[tensor([     3395342848, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139706696204288,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992,\n",
            "                      0, 139702401236992,               0, 139702401236992]), tensor([15046138432, 15080704512, 15080775168, 15080714240, 15065102592,\n",
            "        15080777472, 15080681728, 15080685312, 15080677888, 15080772096,\n",
            "        15080675584,    70345216, 15080768768, 15080675328, 15080703232,\n",
            "        15080678912, 15080774144, 15080779520, 15080775424, 15080675840,\n",
            "        15065103616, 15080681984, 15080774400, 15065103104, 15080770048,\n",
            "        15080779264, 15080673792, 15080769536, 15080678656, 15080772352,\n",
            "        15080773632, 15080775680, 15080684800, 15080681216, 15080783104,\n",
            "        15080769792, 15082236928, 15082237440,  3386153728, 15080773376,\n",
            "        15080780544, 15080676096, 15080685056, 15082228736, 15080682496,\n",
            "        15080684288, 15080669952, 15082228992, 15080670464, 15080679936,\n",
            "        15080670976]), tensor([        15070800896, 4858821049139400704, 5009199055429156864,\n",
            "        4857132199258292224, 4938126623794528256, 5032464721454039040,\n",
            "        4931934174342418432, 4947028269978144768, 5032464721498011648,\n",
            "        5013342015262953472, 4819414552411951104, 4846999100076982272,\n",
            "        4746794008398929920, 4926234306017755136, 5032464721433329664,\n",
            "        4972923967835432960, 4756927107517644800, 4982406156051546112,\n",
            "        5034127183055224832,               28192,                6423,\n",
            "                      22168]), tensor([        15080782592,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                  115935872,                   0,          3386152280,\n",
            "                 3386152296,          3386152320,                  45,\n",
            "                          5,                   5,           135418016,\n",
            "                          0,          3386152344,          3386152360,\n",
            "                 3386152384,                   5,                   1,\n",
            "                          1, 2338340610478596461, 7517387883123860851,\n",
            "                          0,                 225,     139706412747264,\n",
            "        8386828401775764225,           134217729]), tensor([3395342080,      24496,       4209,       7823,      25333,      16616,\n",
            "              9259,      14182,      24496,      14945,      18800,      26009,\n",
            "             15325,      26190,      26260,      17998,      25806,      13823,\n",
            "             15325,      18322,      27334,      14426,      11397,       3411,\n",
            "              2838,      24496,       4234,      16616,       2112,      17880,\n",
            "              9362,      21054,      15341,      31362,      25376,      12626,\n",
            "             29811,      16344,       8899,       3154,      28522,       8831]), tensor([     3364218880,             256,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,   1099511627776, 139705840632064]), tensor([    15046139776,           14188,           13950,           16771,\n",
            "                  21799,            7838,           25393,           16636,\n",
            "                   9273,           28154,           26368,            7838,\n",
            "                  25007,           12354,           33489,            7255,\n",
            "                  16636,            2110,           25007,           18105,\n",
            "                  27810,           17455,           19080,            6951,\n",
            "                  12354,            2682,           26780,           12550,\n",
            "                   9159,           33415,           33489,            7255,\n",
            "                   3867,           27405,           11271,            9082,\n",
            "                   2110,           25007,           28161,            1202,\n",
            "                   9130,            1839,           16923,           16636,\n",
            "                   6951,            7174,           25047,           25007,\n",
            "                  32675,           15944,            8467, 281474976710656,\n",
            "               16842752,               0]), tensor([15070800704,         132,        2459,        6371,        2690,\n",
            "              20636,       11516,       20459,       27141,        2690,\n",
            "              20636,       11516,        8622,       24032,       27991,\n",
            "              22391,       12873,           0,           0,           0,\n",
            "                  0,           0,           0]), tensor([15070800512,         132,        2459,        6371,        2690,\n",
            "              20636,       11516,       20459,       27141,        2690,\n",
            "              20636,       11516,        8622,       24032,       27991,\n",
            "              22391,       12873,           0,           0,           0,\n",
            "                  0,           0]), tensor([15070800320,       28797,        4198,       20962,       22361,\n",
            "               5481,       31827,       16179,       30273,       16636,\n",
            "              25393,       11610,       25516,       14812,        9847,\n",
            "               6423,       21204,       15066,       19458]), tensor([15070800128,       28797,        4198,       20962,       22361,\n",
            "               5481,       31827,       16179,       30273,       16636,\n",
            "              25393,       11610,       25516,       14812,        9847,\n",
            "               6423,       21204,       15066,       19458,           0,\n",
            "                  0,           0]), tensor([15046140224,       14188,       13950,       16771,       21799,\n",
            "               7838,       25393,       16636,        9273,       28154,\n",
            "              26368,        7838,       25007,       12354,       33489,\n",
            "               7255,       16636,        2110,       25007,       18105,\n",
            "              27810,       17455,       19080,        6951,       12354,\n",
            "               2682,       26780,       12550,        9159,       33415,\n",
            "              33489,        7255,        3867,       27405,       11271,\n",
            "               9082,        2110,       25007,       28161,        1202,\n",
            "               9130,        1839,       16923,       16636,        6951,\n",
            "               7174,       25047,       25007,       32675,       15944]), tensor([ 15098127360, 210453397554, 206158430253, 193273528370, 223338299441,\n",
            "        214748364884, 249108103216, 236223201333, 223338299450, 197568495665,\n",
            "        206158430261]), tensor([         3390611072, 2314885436484624428, 7810775710559117344,\n",
            "        7449362198107598438, 7956017156119879525, 8319104318611202151,\n",
            "        7598543858102003553, 7598824251380492142, 8389772277106828643,\n",
            "        7593476290967138365, 7305521827707905390, 8299698051361629284,\n",
            "        3196764479604941160, 8313491484895504672, 8387235707439381097,\n",
            "        7304667507425108338, 7453010313246761581, 6585793593765736051,\n",
            "        6878251651043188017, 7810775836276713843, 7598521950095224422,\n",
            "        8101820029024888186, 7310575238984791407, 8391736009371575357,\n",
            "        8079506545758532191, 7592901220682196065, 3343478956350077028,\n",
            "        6874584755139273072, 7575093194278855785, 8820708198994767982,\n",
            "        4262987330964437605, 8820708198994767648,  732165218811001445,\n",
            "        2314885530818453536, 7094700132581270899, 7306919306986744172,\n",
            "        2338608899871307615, 8241956953416147005]), tensor([    15098125824,               0,     15098127424,               1,\n",
            "                      0,               0,      1065353216,               0,\n",
            "                      0,           14336,       145625192, 139704574563840,\n",
            "                      0,     15098125056,     15082187776,               0]), tensor([        15070799936,                 256,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                          0,   72339069014704128, 4878805772433358848,\n",
            "        4913708669571989504]), tensor([3390610752,    2192697,    2193506,    2193543,    2194455,    2194492,\n",
            "           2194766,    2194803,    2195648,    2195685,    2196434,    2196471,\n",
            "           2197065,    2197102,    2197895,    2197932,    2198332,    2198369,\n",
            "           2199218,    2199255,    2200117,    2200154,    2200733,    2200770,\n",
            "           2201394,    2201431,    2202227,    2202264,    2202640,    2202677,\n",
            "           2203308,    2203345,    2203926]), tensor([15098242560,        9628,        9018,        1114]), tensor([3364222464,        256,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0,\n",
            "                 0,          0,          0,          0,          0,          0]), tensor([15070799744,       29865,       25245,        6371,         510,\n",
            "              17781,       29826,       25403,       16214,       29580,\n",
            "                510,       17781,       21178,       30685,       23596,\n",
            "              31780,       26014,       22684,       15141,        6393,\n",
            "               3105,       12234]), tensor([15070799552,        9939,       25393,       16636,        9273,\n",
            "               1504,        4056,       25393,       19489,        6750,\n",
            "               3662,       16143,       16636,        9273,        2559,\n",
            "              25131,       19489,       16636,        9273,       32505,\n",
            "              31542]), tensor([15098242432,       23878,        9018]), tensor([     3395341312, 139705842599784, 139705804175792, 139705842599840,\n",
            "        139705804175856, 139705842600064, 139705842600344, 139705842599728,\n",
            "        139705804175920, 139705842599280, 139705842599168, 139705804175984,\n",
            "        139705842598720, 139705804176048, 139705804176112, 139705804176176,\n",
            "        139705804176240, 139705842598664, 139705804176304, 139705842598552,\n",
            "        139705842598496, 139705804176368, 139705804176432, 139705842598216,\n",
            "        139705842598104, 139705842601296, 139705804176496, 139705804176560,\n",
            "        139705804176624, 139705842601184, 139705804176688, 139705842600568,\n",
            "        139705804176752, 139705842598384, 139705842600456, 139705842598888,\n",
            "        139705804176816, 139705804176880, 139705842598328, 139705842598160,\n",
            "        139705804176944, 139705842601464]), tensor([           29797568, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016,\n",
            "        4629700418014806016, 4629700418014806016, 4629700418014806016]), tensor([15098242368]), tensor([    15098119168,               0,     15098125888,               1,\n",
            "                      0,               0,      1065353216,               0,\n",
            "                      0,          143360,       145625192, 139704574882304]), tensor([      123418880,             256,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,               0,               0,               0,\n",
            "                      0,   1099511627776,       -16711424,               0,\n",
            "        139708217467072,               0]), tensor([15098242304,        9116,       22053,       23080,       25333]), tensor([          0, 15082230016, 15082235648, 15082233856, 15080679936,\n",
            "        15082226688, 15082240256, 15082237184, 15082226176, 15082235392,\n",
            "        15082234112, 15080706304, 15082239488, 15080685056, 15080670208,\n",
            "        15082232320, 15080669952, 15080682496, 15082237952, 15080711680,\n",
            "        15080702976, 15080777984, 15080713984, 15080673280, 15080774912,\n",
            "        15080715264, 15080768256,  3386139392, 15082233088, 15080781824,\n",
            "        15080707840, 15080713728, 15080677120]), tensor([        15098242240,               20921,                4068,\n",
            "                       9018,               18835, 7310305785198503009,\n",
            "                    6579456]), tensor([        15082228224,                   0,                   0,\n",
            "                          0,                   0,                   0,\n",
            "                  115864672,                   0,         15080675928,\n",
            "                15080675944,         15080675968,                  68,\n",
            "                          5,                   1,                   1,\n",
            "        5634005882734314777,         15080675992,         15080676008,\n",
            "                15080676032,                   5,                   1,\n",
            "                          1,                   1, 5620495083851159557,\n",
            "                          0,                 340]), tensor([         3390609792, 8820708198994767648, 2314861629325647973,\n",
            "        7310221942502465568, 7594305241310193260, 4404652808228267886,\n",
            "        7453010313246502944, 2314885437810043231, 7810775710559117344,\n",
            "        8388068008349085286, 2339735946718702943, 8241956953416147005,\n",
            "        8370065687538134369, 7953763960558416495, 8247328359804595812,\n",
            "        7882811607585024353, 8315736635897832802, 3484490270046188334,\n",
            "        8247328359804054621, 7882811607585024353, 8315736635897832802,\n",
            "        3484490270046188334, 8946435995007002973, 2989359343782886486,\n",
            "        2314885530818453536, 2314885530818453514, 7882757740222051104,\n",
            "        2334956330749814114, 7092401053901922365, 7362936164709590117,\n",
            "        8387235708010327922, 8081819918123229554, 7308895112521868658,\n",
            "        7234018374880419684, 8243311543235079785, 7809600458346620261])]\n",
            "tensor([[         3395342848,     139702401236992,                   0,\n",
            "          ...,                   1,                   1,\n",
            "                           1],\n",
            "        [        15046138432,         15080704512,         15080775168,\n",
            "          ...,                   1,                   1,\n",
            "                           1],\n",
            "        [        15070800896, 4858821049139400704, 5009199055429156864,\n",
            "          ...,                   1,                   1,\n",
            "                           1],\n",
            "        ...,\n",
            "        [        15098242240,               20921,                4068,\n",
            "          ...,                   1,                   1,\n",
            "                           1],\n",
            "        [        15082228224,                   0,                   0,\n",
            "          ...,                   1,                   1,\n",
            "                           1],\n",
            "        [         3390609792, 8820708198994767648, 2314861629325647973,\n",
            "          ...,                   1,                   1,\n",
            "                           1]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-3c47fd2f9fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_edge_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8JgUousm6mi",
        "outputId": "af9df70a-fd64-4745-fa9e-c0e7ff042a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 15046138432, 137438953504, 137438953504, 137438953504, 433791697010,\n",
              "        137438953588, 137438953533, 476741369972, 425201762418, 197568495720,\n",
              "        287762808927, 408021893166, 472446402670, 472446402606, 463856468076,\n",
              "        463856468063, 493921239151, 214748364915, 171798691940, 472446402665,\n",
              "        502511173744, 188978561140, 498216206368, 489626271841, 433791696999,\n",
              "        188978561140, 511101108256, 450971566181, 446676598887, 188978561140,\n",
              "        408021893152, 433791696978, 502511173732, 498216206435, 476741369961,\n",
              "        197568495726, 433791696999, 408021893236, 472446402661, 468151435381,\n",
              "        489626271784, 429496729701, 425201762421, 450971566196, 472446402671,\n",
              "        188978561065, 450971566112, 472446402663, 489626271855, 408021893221,\n",
              "        472446402665, 433791696996, 176093659256,  14995387984,            1],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSEFPP0P3bD",
        "outputId": "2c8249d2-08a0-4cf0-c963-c5e33ec11606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "le.transform(le.classes_)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxWc3bD_P9VJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}